{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from skimage import color\n",
    "\n",
    "from utils import grainPreprocess, grainShow, grainMark, grainDraw, grainApprox, grainStats, grainMorphology,grainGenerate\n",
    "from utils import SEMDataset\n",
    "\n",
    "from crdp import rdp\n",
    "from skimage import io, filters, morphology, util\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from multiprocessing import Lock, Process, Queue, current_process\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEMDataset(Dataset):\n",
    "    def __init__(self, images_folder_path, no_cache=False, max_images_num_per_class=10, workers=None):\n",
    "        \n",
    "        self.cached_dir = 'tmp/'+ images_folder_path.split('/')[-1]\n",
    "        \n",
    "        if workers is None:\n",
    "            workers = multiprocessing.cpu_count()-1\n",
    "        \n",
    "        if images_folder_path[-1]=='/':\n",
    "            raise ValueError('remove last \"/\" in path ')\n",
    "        \n",
    "        if os.path.exists(self.cached_dir) is False or no_cache:\n",
    "            \n",
    "            Path(self.cached_dir).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            folders_paths = glob.glob(images_folder_path + '/*')\n",
    "            images_paths = []\n",
    "            \n",
    "            for folder_path in folders_paths:\n",
    "                images_paths.extend(glob.glob(folder_path + '/*')[:max_images_num_per_class])\n",
    "                folder_name = folder_path.split('/')[-1]\n",
    "                \n",
    "                new_folder_path = self.cached_dir + '/' + folder_name\n",
    "                Path(new_folder_path).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            number_of_tasks = len(folders_paths)\n",
    "            images_paths = np.array(images_paths).reshape((number_of_tasks,-1))\n",
    "\n",
    "            tasks_to_accomplish = Queue()\n",
    "            tqdm_queue = Queue()\n",
    "            processes = []\n",
    "        \n",
    "            for i in range(number_of_tasks):\n",
    "                tasks_to_accomplish.put(images_paths[i])\n",
    "            \n",
    "            for w in range(workers):\n",
    "                p = Process(target=self.do_job, args=(tasks_to_accomplish,self.cached_dir,tqdm_queue))\n",
    "                processes.append(p)\n",
    "                p.start()\n",
    "                \n",
    "            total = images_paths.shape[0]*images_paths.shape[1]\n",
    "                \n",
    "            with tqdm(total=total) as pbar:\n",
    "                completed = 0\n",
    "                while completed < total:\n",
    "                    tqdm_queue.get()\n",
    "                    pbar.update(1)\n",
    "                    completed += 1\n",
    "\n",
    "            for p in processes:\n",
    "                p.join()\n",
    "        \n",
    "            # pbar.close()\n",
    "            \n",
    "        folders_paths = glob.glob(self.cached_dir + '/*')\n",
    "        folder_names= [folder_path.split('/')[-1] for folder_path in folders_paths] \n",
    "            \n",
    "        self.images_paths = np.array([glob.glob(self.cached_dir + f'/{folder_name}/*')[:max_images_num_per_class] for folder_name in folder_names])\n",
    "    \n",
    "    @classmethod\n",
    "    def do_job(self, tasks_to_accomplish, cached_dir, tqdm_queue):\n",
    "        while not tasks_to_accomplish.empty():\n",
    "            images_paths = tasks_to_accomplish.get()\n",
    "            for image_path in images_paths:\n",
    "                image = io.imread(image_path)\n",
    "                image = self.preprocess_image(image)\n",
    "\n",
    "                splitted=image_path.split('/')\n",
    "                folder_name, file_name = splitted[-2], splitted[-1]\n",
    "                file_name = file_name.split('.')[0]\n",
    "\n",
    "                io.imsave(cached_dir + '/' + folder_name + '/' + file_name + '.png', image)\n",
    "                tqdm_queue.put(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "\n",
    "    def __getitem__(self, class_idx, idx):\n",
    "        path = self.images_paths[class_idx, idx]\n",
    "        image = io.imread(path)\n",
    "        return image, path\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_image(self, image):\n",
    "        if len(image.shape)==3:\n",
    "            image = color.rgb2gray(image)\n",
    "        \n",
    "        image = filters.rank.median(image, morphology.disk(3))\n",
    "\n",
    "        global_thresh = filters.threshold_otsu(image)\n",
    "        image = image > global_thresh\n",
    "        binary = image*255\n",
    "        binary = binary.astype(np.uint8)\n",
    "\n",
    "        grad = abs(filters.rank.gradient(binary, morphology.disk(1)))\n",
    "        bin_grad = (1 - binary + grad) * 127\n",
    "        bin_grad = np.clip(bin_grad, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return bin_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Углы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def angles_approx_save(images_path, save_path, types_dict, step, max_images_num_per_class=None, no_cache=False, workers=None):\n",
    "\n",
    "    #\n",
    "    # вычисление и сохранение распределения углов для всех фотографий одного образца\n",
    "    #\n",
    "\n",
    "    json_data = []\n",
    "    \n",
    "    dataset = SEMDataset(images_path, no_cache=no_cache, max_images_num_per_class=max_images_num_per_class, workers=workers)\n",
    "    shape=dataset.images_paths.shape\n",
    "    \n",
    "    pbar = tqdm(total=shape[0]*shape[1])\n",
    "\n",
    "    for i in range(dataset.images_paths.shape[0]):\n",
    "        all_angles = []\n",
    "        \n",
    "        for j in range(dataset.images_paths.shape[1]):\n",
    "            image, path = dataset.__getitem__(i,j)\n",
    "            ang=grainMark.get_angles(image, tol=3)\n",
    "            all_angles.extend(ang)\n",
    "            pbar.update(1)\n",
    "\n",
    "        x, y = grainStats.stats_preprocess(all_angles, step)\n",
    "\n",
    "        (x_gauss, y_gauss), mus, sigmas, amps = grainApprox.bimodal_gauss_approx(x, y)\n",
    "        name = path.split('/')[-2]\n",
    "\n",
    "        text = grainGenerate.angles_legend(dataset.images_paths.shape[1], types_dict[name], types_dict[name], step, mus, sigmas,amps, len(all_angles) )\n",
    "        \n",
    "        path='/'.join(path.split('/')[:-1])\n",
    "\n",
    "        json_data.append({'path': path,\n",
    "                          'name': name,\n",
    "                          'type': types_dict[name],\n",
    "                          'legend': text,\n",
    "                          'density_curve_scatter': [x,y],\n",
    "                          'gauss_approx_plot': [x_gauss, y_gauss],\n",
    "                          'gauss_approx_data': {'mus': mus, 'sigmas':sigmas, 'amps':amps},\n",
    "                          })\n",
    "\n",
    "    with open(f'{save_path}_step_{step}_angles.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(json_data, outfile, cls=grainGenerate.NumpyEncoder, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "step = 5\n",
    "\n",
    "# images_path = '../ml/diffusion/data/o_bc_left_4x_768_360_768_median_generated'\n",
    "# images_path = '../ml/diffusion/data/o_bc_left_4x_768_360_512_median_generated'\n",
    "# images_path = '../ml/diffusion/data/o_bc_left_4x_768_360_256_median_generated'\n",
    "\n",
    "images_path = '../datasets/original/o_bc_left'\n",
    "\n",
    "# save_path = 'o_bc_left_4x_768_360_median_generated_preprocess'\n",
    "# save_path = 'o_bc_left_4x_768_360_256_median_generated_preprocess'\n",
    "# save_path = 'o_bc_left_4x_768_360_768_median_generated'\n",
    "# save_path = 'o_bc_left_4x_768'\n",
    "save_path = 'test12'\n",
    "\n",
    "types_dict = {'Ultra_Co11': 'средние зерна',\n",
    "              'Ultra_Co25': 'мелкие зерна',\n",
    "              'Ultra_Co8': 'средне-мелкие зерна',\n",
    "              'Ultra_Co6_2': 'крупные зерна',\n",
    "              'Ultra_Co15': 'средне-мелкие зерна'}\n",
    "\n",
    "angles_approx_save(\n",
    "                    images_path=images_path,\n",
    "                    save_path=save_path,\n",
    "                    types_dict=types_dict,\n",
    "                    step=step,\n",
    "                    max_images_num_per_class=None, \n",
    "                    no_cache=False,\n",
    "                    workers = 5\n",
    "                )\n",
    "\n",
    "file_name=f'{save_path}_step_{step}_angles.json'\n",
    "\n",
    "data = open(file_name,encoding='utf-8')\n",
    "data = json.load(data)\n",
    "\n",
    "grainShow.angles_plot_base(data,save_name=file_name, step=step, N=10, M=7, indices=[2,0,1], save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полуоси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pixel = 50 / 1000\n",
    "\n",
    "# images_path = '../ml/diffusion/data/o_bc_left_4x_768_360_768_median_generated'\n",
    "# images_path = '../ml/diffusion/data/o_bc_left_4x_768_360_512_median_generated'\n",
    "images_path = '../ml/diffusion/data/o_bc_left_4x_768_360_256_median_generated'\n",
    "\n",
    "save_path = 'o_bc_left_4x_768_360_256_median_generated'\n",
    "\n",
    "\n",
    "types_dict = {'Ultra_Co11': 'средние зерна',\n",
    "              'Ultra_Co25': 'мелкие зерна',\n",
    "              'Ultra_Co8': 'средне-мелкие зерна',\n",
    "              'Ultra_Co6_2': 'крупные зерна',\n",
    "              'Ultra_Co15': 'средне-мелкие зерна'}\n",
    "\n",
    "\n",
    "for step in range(5, 6):\n",
    "    grainGenerate.diametr_approx_save(\n",
    "    # diametr_approx_save(\n",
    "                        images_path=images_path,\n",
    "                        save_path=save_path,\n",
    "                        types_dict=types_dict,\n",
    "                        step=step,\n",
    "                        max_images_num_per_class=None, \n",
    "                        no_cache=False,\n",
    "                        pixel = pixel\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('images_7_classes_mixer_preprocess.npy')\n",
    "names = np.load('metadata_7_classes_mixer_preprocess.npy')\n",
    "names = [name.split('\\\\')[-1] for name in names]\n",
    "\n",
    "folder = 'data/'\n",
    "\n",
    "types_dict = {'2550-51': '2550 призм, кадр 51\\n доля карбина 54.51%',\n",
    "              '2550-52': '2550 призм, кадр 52\\n доля карбина 50.75%',\n",
    "              '2550-53': '2550 призм, кадр 53\\n доля карбина 45.81%',\n",
    "              '3400-51': '3400 призм, кадр 51\\n доля карбина 53.53%',\n",
    "              '3400-52': '3400 призм, кадр 52\\n доля карбина 50.47%',\n",
    "              '3400-53': '3400 призм, кадр 53\\n доля карбина 45.88%',\n",
    "              '3400-54': '3400 призм, кадр 54\\n доля карбина 40.88%'}\n",
    "\n",
    "dens_dict={'2550-51': 0.5451066158234127,\n",
    "           '2550-52': 0.5075556821469908,\n",
    "           '2550-53': 0.4580166661499669,\n",
    "           '3400-51': 0.535331783234127,\n",
    "           '3400-52': 0.504782962859623,\n",
    "           '3400-53': 0.45885131190062833,\n",
    "           '3400-54': 0.40882115988756607}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
