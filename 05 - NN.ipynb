{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "from src.nn import U2NET\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from skimage import transform, metrics\n",
    "from umap import UMAP\n",
    "import datetime\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import io\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "import plotly.express as px\n",
    "\n",
    "from src.nn_utils import SaveImageCallback\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_images = np.load('data/saved np/all_images_no_preprocess.npy', allow_pickle=True)\n",
    "all_images_rgb = []\n",
    "for i, images_list in enumerate(all_images):\n",
    "    for image_gray in images_list:\n",
    "        tf_image = tf.expand_dims(image_gray / 255, 2)\n",
    "        #    tf_rgb = tf.image.grayscale_to_rgb(tf_image)\n",
    "        tf_preproc = tf.image.resize(tf_image, (1024, 1024))\n",
    "        all_images_rgb.append(tf_preproc)\n",
    "\n",
    "all_images_rgb = np.array(all_images_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "image_shape = (1024, 1024, 1)\n",
    "inputs = tf.keras.Input(shape=image_shape)\n",
    "net = U2NET(1)\n",
    "out = net(inputs)\n",
    "# net.built=True\n",
    "# net.load_weights('data/saved_models/u2net_loss=0.0089.h5')\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=out[0], name='u2netmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "BATCH_SIZE_PER_REPLICA = 1\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "with strategy.scope():\n",
    "    image_shape = (1024, 1024, 1)\n",
    "    inputs = tf.keras.Input(shape=image_shape)\n",
    "    net = U2NET(1)\n",
    "    out = net(inputs)\n",
    "    net.built = True\n",
    "    net.load_weights('data/saved_models/u2netP_loss=0.0027.h5')\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out[0], name='u2netmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_images_rgb[:100], all_images_rgb[:100], test_size=0.2)\n",
    "name = f'u2net_{datetime.datetime.now().date()}'\n",
    "log_dir = f'data/logs/{name}_tensorboard/'\n",
    "checkpoint_filepath = f'data/logs/{name}_checkpoint/checkpoints/'\n",
    "csv_log_path = f'data/logs/train_csv/'\n",
    "csv_log_filepath = csv_log_path + f'{name}.csv'\n",
    "images_save_dir = f'data/logs/{name}_val_images/'\n",
    "\n",
    "if not os.path.exists(csv_log_filepath):\n",
    "    os.makedirs(csv_log_filepath)\n",
    "\n",
    "if not os.path.exists(csv_log_filepath):\n",
    "    with open(csv_log_filepath, 'wb') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='#', quoting=csv.QUOTE_MINIMAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.1, epsilon=1e-07, centered=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(csv_log_filepath)\n",
    "\n",
    "n_samples = 3\n",
    "\n",
    "save_callback = SaveImageCallback(x_test, images_save_dir, n_samples, net)\n",
    "\n",
    "model.compile(optimizer=optim, loss='mse', metrics=['MAE'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=2,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, x_test),\n",
    "                    callbacks=[tensorboard_callback,\n",
    "                               model_checkpoint_callback,\n",
    "                               early_stop_callback,\n",
    "                               csv_logger,\n",
    "                               save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predict=model.predict(tf.expand_dims(all_images_rgb[0],axis=0))[0]\n",
    "n = 1\n",
    "\n",
    "predict = net(tf.expand_dims(x_test[n], axis=0))[0][0]\n",
    "\n",
    "original = x_test[n]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax1.imshow(predict, cmap='gray')\n",
    "ax1.set_title('Autoencoder', fontsize=15)\n",
    "\n",
    "ax2.imshow(original, cmap='gray')\n",
    "ax2.set_title('Original', fontsize=15)\n",
    "#plt.savefig(f'autoencoder{name}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net(tf.expand_dims(images_no_filters[0], axis=0))[1][0].numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_shape = (1024, 1024, 1)\n",
    "inputs = tf.keras.Input(shape=image_shape)\n",
    "net = U2NET(1)\n",
    "out = net(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=out[0], name='u2netmodel')\n",
    "model.built = True\n",
    "model.load_weights('data/logs/u2net_2021-11-19_checkpoint/checkpoints/')\n",
    "images = np.load('data/saved np/all_images_no_preprocess.npy', allow_pickle=True)\n",
    "name = f'u2net_{datetime.datetime.now().date()}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse_losses = []\n",
    "ssim_losses = []\n",
    "\n",
    "for i, images_list in enumerate(images):\n",
    "    for image in images_list:\n",
    "        original_image = transform.resize(image, image_shape)\n",
    "        predicted_image = model.predict(tf.expand_dims(original_image, axis=0))[0]\n",
    "        mse_losses.append(metrics.mean_squared_error(original_image, predicted_image))\n",
    "        ssim_losses.append(metrics.structural_similarity(original_image, predicted_image, multichannel=True))\n",
    "        mse_losses = np.array(mse_losses)\n",
    "\n",
    "ssim_losses = np.array(ssim_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n",
    "\n",
    "names = ['Ultra_Co8\\nсредние зерна', 'Ultra_Co11\\nмелкие зерна', 'Ultra_Co6_2\\nмелкие зерна',\n",
    "         'Ultra_Co15\\nкрупные зерна', 'Ultra_Co25\\nсредне-мелкие зерна']\n",
    "\n",
    "colors = ['b', 'g', 'y', 'm', 'c']\n",
    "markers = ['8', 'v', 's', 'd', '*', ]\n",
    "\n",
    "f_vects = []\n",
    "\n",
    "for i, images_list in enumerate(images):\n",
    "    start = 0\n",
    "    for j in range(i):\n",
    "        start += len(images[j])\n",
    "    end = start + len(images_list)\n",
    "\n",
    "    x = np.arange(mse_losses.shape[0])[start:end]\n",
    "    mse_y = mse_losses[start:end]\n",
    "    ssim_y = ssim_losses[start:end]\n",
    "\n",
    "    ax1.plot(x, mse_y)\n",
    "    ax1.scatter(x, mse_y)\n",
    "\n",
    "    ax2.plot(x, ssim_y)\n",
    "    ax2.scatter(x, ssim_y)\n",
    "\n",
    "plt.rcParams['font.size'] = '20'\n",
    "\n",
    "ax1.legend(names, fontsize=15)\n",
    "ax1.set_title('MSE image losses', fontsize=20)\n",
    "ax1.set_xlabel('image number', fontsize=20)\n",
    "ax1.set_ylabel('MSE loss', fontsize=20)\n",
    "\n",
    "ax2.legend(names, fontsize=15)\n",
    "ax2.set_title('Structural image similarity', fontsize=20)\n",
    "ax2.set_xlabel('image number', fontsize=20)\n",
    "ax2.set_ylabel('SSIM similarity', fontsize=20)\n",
    "\n",
    "plt.savefig(f'mse_ssim_losses_{name}.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_shape = (1024, 1024, 1)\n",
    "inputs = tf.keras.Input(shape=image_shape)\n",
    "net = U2NET(1)\n",
    "out = net(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=out[0], name='u2netmodel')\n",
    "model.built = True\n",
    "model.load_weights('data/logs/u2net_2021-11-19_checkpoint/checkpoints/')\n",
    "images = np.load('data/saved np/images_no_filters.npy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images = np.load('data/saved np/images_no_filters.npy')\n",
    "images_embs = []\n",
    "for i, images_list in enumerate(images):\n",
    "\n",
    "    images_embs.append([])\n",
    "    for image_gray in images_list:\n",
    "        emb = net(tf.expand_dims(image_gray / 255, axis=0))[1][0].numpy().flatten()\n",
    "        images_embs[i].append(emb)\n",
    "\n",
    "\n",
    "images_embs=np.array(images_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('data/saved np/images_embs.npy', images_embs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# вывод фильтров свертки\n",
    "\n",
    "image = images[0][0]\n",
    "img = net(tf.expand_dims(image / 255, axis=0))\n",
    "\n",
    "for level in range(1, 7):\n",
    "    filters = img[level][0].numpy()\n",
    "\n",
    "    filters_num = filters.shape[-1]\n",
    "    n_rows = int(math.sqrt(filters_num))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_rows, figsize=(20, 20))\n",
    "    step = 0\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_rows):\n",
    "            ax[i][j].imshow(filters[:, :, step], cmap='gray')\n",
    "            step += 1\n",
    "    # plt.savefig(f'cnn_filters_level_{6 - level}.png')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_embs = np.load('data/saved np/images_embs.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 51\n",
    "umap_2d = UMAP(random_state=seed)\n",
    "old_shape=images_embs.shape\n",
    "umaped_vct_2d = umap_2d.fit_transform(images_embs.reshape(-1,images_embs.shape[-1]))\n",
    "legend = ['Ultra_Co8\\nсредние зерна', 'Ultra_Co11\\nмелкие зерна', 'Ultra_Co6_2\\nмелкие зерна',\n",
    "          'Ultra_Co15\\nкрупные зерна', 'Ultra_Co25\\nсредне-мелкие зерна']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_2d_scatter(images, legend, dot_size=20, fontsize=15, save=False, plot=True, N=15, M=15):\n",
    "N=15\n",
    "M=15\n",
    "fontsize=15\n",
    "dot_size=20\n",
    "\n",
    "embs_scatter=umaped_vct_2d.reshape((5,90,-1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(N, M))\n",
    "\n",
    "colors = ['b', 'g', 'y', 'm', 'c']\n",
    "markers = ['8', 'v', 's', 'd', '*', ]\n",
    "\n",
    "f_vects = []\n",
    "\n",
    "for i,emb_vects  in enumerate(embs_scatter):\n",
    "    ax.scatter(emb_vects[:,0],emb_vects[:,1], edgecolor=colors[i], s=dot_size,marker=markers[i])\n",
    "\n",
    "ax.legend(legend, fontsize=fontsize)\n",
    "# plt.savefig(f'embs_space_seed={seed}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_emb_distr(step, projection_axis, eps):\n",
    "    axis_start = f_vects[0][projection_axis].min()\n",
    "    axis_end = f_vects[0][projection_axis].max()\n",
    "\n",
    "    for vects in f_vects:\n",
    "        min_val = vects[projection_axis].min()\n",
    "        max_val = vects[projection_axis].max()\n",
    "\n",
    "        if min_val < axis_start:\n",
    "            axis_start = min_val\n",
    "\n",
    "        if max_val > axis_end:\n",
    "            axis_end = max_val\n",
    "\n",
    "    axis_step = step * (axis_end - axis_start)\n",
    "    axis_eps = eps * (axis_end - axis_start)\n",
    "    axis_vals = np.arange(axis_start, axis_end, axis_step)\n",
    "\n",
    "    points_distr = []\n",
    "\n",
    "    for i, vects in enumerate(f_vects):\n",
    "        points_distr.append([])\n",
    "        for axis_val in axis_vals:\n",
    "            counter = 0\n",
    "            for point in vects[projection_axis]:\n",
    "                if abs(point - axis_val) <= axis_eps:\n",
    "                    counter += 1\n",
    "            points_distr[i].append(counter)\n",
    "\n",
    "    for i, distr in enumerate(points_distr):\n",
    "        points_distr[i] = np.array(points_distr[i]) / sum(distr)\n",
    "\n",
    "    return axis_vals, np.array(points_distr), axis_step, axis_eps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "names = ['Ultra_Co8\\nсредние зерна', 'Ultra_Co11\\nмелкие зерна', 'Ultra_Co6_2\\nмелкие зерна',\n",
    "         'Ultra_Co15\\nкрупные зерна', 'Ultra_Co25\\nсредне-мелкие зерна']\n",
    "\n",
    "colors = ['b', 'g', 'y', 'm', 'c']\n",
    "markers = ['8', 'v', 's', 'd', '*', ]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 20))\n",
    "\n",
    "step = 0.05\n",
    "# eps=step/2\n",
    "eps = 0.25\n",
    "projection_axis = 1\n",
    "\n",
    "x_axis_vals, x_points_distr, x_step, x_eps = get_emb_distr(step, projection_axis=0, eps=eps)\n",
    "y_axis_vals, y_points_distr, y_step, y_eps = get_emb_distr(step, projection_axis=1, eps=eps)\n",
    "\n",
    "for i in range(len(x_points_distr)):\n",
    "    # y projection\n",
    "    ax1.scatter(y_axis_vals, y_points_distr[i], edgecolor=colors[i], s=size, marker=markers[i])\n",
    "    ax1.plot(y_axis_vals, y_points_distr[i], color=colors[i])\n",
    "    ax1.legend(names + [\n",
    "        f'шаг={round(y_step, 2)}, доля от длины оси={int(step * 100)}%\\neps={round(y_eps, 2)}, доля от длины оси={int(eps * 100)}%'],\n",
    "               fontsize=15)\n",
    "    ax1.set_xlabel('y val', fontsize=20)\n",
    "    ax1.set_ylabel('norm(count)', fontsize=20)\n",
    "\n",
    "    # x prjection\n",
    "    ax2.scatter(x_axis_vals, x_points_distr[i], edgecolor=colors[i], s=size, marker=markers[i])\n",
    "    ax2.plot(x_axis_vals, x_points_distr[i], color=colors[i])\n",
    "    ax2.legend(names + [\n",
    "        f'шаг={round(x_step, 2)}, доля от длины оси={int(step * 100)}%\\neps={round(x_eps, 2)}, доля от длины оси={int(eps * 100)}%'],\n",
    "               fontsize=15)\n",
    "    ax2.set_xlabel('x val', fontsize=20)\n",
    "    ax2.set_ylabel('norm(count)', fontsize=20)\n",
    "\n",
    "plt.savefig(f'embs projection step={step} eps={eps}.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_3d = UMAP(n_components=3)\n",
    "umaped_vct_3d = umap_3d.fit_transform(images_embs.reshape(-1,images_embs.shape[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "size = 20\n",
    "\n",
    "names = ['Ultra_Co8\\nсредние зерна', 'Ultra_Co11\\nмелкие зерна', 'Ultra_Co6_2\\nмелкие зерна',\n",
    "         'Ultra_Co15\\nкрупные зерна', 'Ultra_Co25\\nсредне-мелкие зерна']\n",
    "\n",
    "colors = ['b', 'g', 'y', 'm', 'c']\n",
    "markers = ['8', 'v', 's', 'd', '*', ]\n",
    "\n",
    "\n",
    "embs_3d_scatter=umaped_vct_3d.reshape((5,90,-1))\n",
    "\n",
    "scatters = []\n",
    "for i, scatter_list in enumerate(embs_3d_scatter):\n",
    "\n",
    "    for point in scatter_list:\n",
    "        scatters.append([point[0], point[1], point[2], 0.2, names[i], i + 1])\n",
    "\n",
    "column_values = ['x', 'y', 'z', 'width', 'name', 'class']\n",
    "\n",
    "# creating the dataframe\n",
    "df = pd.DataFrame(data=scatters,\n",
    "                  columns=column_values)\n",
    "\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                    color='name')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}