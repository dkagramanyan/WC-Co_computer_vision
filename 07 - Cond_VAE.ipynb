{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from skimage import transform, metrics\n",
    "from umap import UMAP\n",
    "import datetime\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import io\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "import plotly.express as px\n",
    "\n",
    "from src.nn import ConvCVAE, Decoder, Encoder\n",
    "from src.nn import RSU7, RSU6, RSU5, RSU4, RSU4F, ConvBlock\n",
    "from src.nn_utils import SaveImageCallback\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.prod((64, 64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_dim = 40\n",
    "image_dim = [64, 64, 3]\n",
    "latent_dim = 128\n",
    "beta = 0.65\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "train_size = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "# Model\n",
    "encoder = Encoder(latent_dim)\n",
    "decoder = Decoder()\n",
    "model = ConvCVAE(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    label_dim=label_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    beta=beta,\n",
    "    image_dim=image_dim)\n",
    "\n",
    "# Optiizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_shape = (1024, 1024, 1)\n",
    "latent_dim = 200\n",
    "\n",
    "inputs = tf.keras.Input(shape=image_shape)\n",
    "encoder = Encoder(latent_dim, label_dim=5)\n",
    "out = encoder(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, label_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage1 = RSU7(16, 64)\n",
    "        self.pool12 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage2 = RSU6(32, 64)\n",
    "        self.pool23 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage3 = RSU5(64, 128)\n",
    "        self.pool34 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage4 = RSU4(128, 256)\n",
    "        self.pool45 = layers.MaxPool2D((2, 2), 2)\n",
    "        #out_w_h=64\n",
    "\n",
    "        self.stage5 = RSU4F(256, 512)\n",
    "        self.pool56 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Encoder block 1\n",
    "\n",
    "        input_image, input_label = inputs\n",
    "\n",
    "        hx1 = self.stage1(inputs[0])\n",
    "\n",
    "        hx = self.pool12(hx1)\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        hx5 = self.stage5(hx)\n",
    "        x = self.pool56(hx5)\n",
    "        global_pool = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(global_pool)\n",
    "        x = tf.keras.layers.Dense(512)(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(self.latent_dim * 2)(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "\n",
    "        x_label = layers.Dense(128)(global_pool)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim, name='encoder_label_output')(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        return x, x_label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = (200,)\n",
    "label_dim = (5,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_dim=200, label_dim=5)\n",
    "image_input = layers.Input(shape=(1024, 1024, 1))\n",
    "label_input = layers.Input(shape=(5,))\n",
    "\n",
    "outputs = encoder([image_input, label_input])\n",
    "model = tf.keras.Model(inputs=[image_input, label_input], outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, label_dim, batch_size=32, out_ch=1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage6 = RSU4F(256, 512)\n",
    "        self.stage5d = RSU4F(256, 512)\n",
    "        self.stage4d = RSU4(128, 256)\n",
    "        self.stage3d = RSU5(64, 128)\n",
    "        self.stage2d = RSU6(32, 64)\n",
    "        self.stage1d = RSU7(16, out_ch)\n",
    "\n",
    "        self.upsample_1 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_2 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_3 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_4 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_5 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_6 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear', name='rec_image_output')\n",
    "\n",
    "    def __call__(self, z_inputs):\n",
    "        # Reshape input\n",
    "        # z_image_v, labels = tf.split(z_inputs, axis=1, num_or_size_splits=2)\n",
    "        z_data = tf.concat(z_inputs, axis=1)\n",
    "        x = layers.Dense(256)(z_data)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = layers.Reshape(target_shape=(16, 16, 1))(x)\n",
    "\n",
    "        hx6 = self.stage6(x)\n",
    "        hx6up = self.upsample_6(hx6)\n",
    "\n",
    "        max_pool = layers.GlobalAveragePooling2D()(hx6up)\n",
    "        x_label = layers.Dense(128)(max_pool)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim, name='rec_label_output')(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        hx5d = self.stage5d(hx6up)\n",
    "        hx5dup = self.upsample_5(hx5d)\n",
    "\n",
    "        hx4d = self.stage4d(hx5dup)\n",
    "        hx4dup = self.upsample_4(hx4d)\n",
    "\n",
    "        hx3d = self.stage3d(hx4dup)\n",
    "        hx3dup = self.upsample_3(hx3d)\n",
    "\n",
    "        hx2d = self.stage2d(hx3dup)\n",
    "        hx2dup = self.upsample_2(hx2d)\n",
    "\n",
    "        hx1d = self.stage1d(hx2dup)\n",
    "        x = self.upsample_1(hx1d)\n",
    "\n",
    "        x = activations.sigmoid(x)\n",
    "\n",
    "        return x, x_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = (200,)\n",
    "label_dim = (5,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoder = Decoder(label_dim=5)\n",
    "z_input = layers.Input(shape=latent_dim)\n",
    "label_input = layers.Input(shape=label_dim)\n",
    "outputs = decoder([z_input, label_input])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[z_input, label_input], outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ConvCVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 label_dim,\n",
    "                 latent_dim,\n",
    "                 image_dim,\n",
    "                 beta=1,\n",
    "                 ):\n",
    "        super(ConvCVAE, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.label_dim = label_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.image_dim = image_dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        input_img, input_label = inputs\n",
    "\n",
    "        z_latent, enc_labels = self.encoder(inputs=(input_img, input_label))\n",
    "        z_mean, z_log_var = tf.split(z_latent, num_or_size_splits=2, axis=1)\n",
    "        z_cond = self.reparametrization(z_mean, z_log_var)\n",
    "        logits, dec_labels = self.decoder((z_cond, input_label))\n",
    "\n",
    "        recon_img = tf.nn.sigmoid(logits)\n",
    "\n",
    "        # return recon_img,enc_labels,dec_labels\n",
    "\n",
    "        # Loss computation #\n",
    "        latent_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var),\n",
    "                                            axis=-1)  # KL divergence\n",
    "\n",
    "        # очень странная метрика для изображений\n",
    "        # np.prod((64, 64)) *\n",
    "        reconstr_loss = tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "                                            tf.keras.backend.flatten(\n",
    "                                                recon_img))\n",
    "        enc_label_loss = tf.losses.MSE(tf.keras.backend.flatten(input_label), tf.keras.backend.flatten(enc_labels)\n",
    "                                       )\n",
    "        dec_label_loss = tf.losses.MSE(tf.keras.backend.flatten(input_label), tf.keras.backend.flatten(dec_labels)\n",
    "                                       )\n",
    "        loss = reconstr_loss + enc_label_loss + dec_label_loss + self.beta * latent_loss  # weighted ELBO loss\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        return {\n",
    "            'recon_img': recon_img,\n",
    "            'latent_loss': latent_loss,\n",
    "            'reconstr_loss': reconstr_loss,\n",
    "            'enc_label_loss': enc_label_loss,\n",
    "            'dec_label_loss': dec_label_loss,\n",
    "            'loss': loss,\n",
    "            'z_mean': z_mean,\n",
    "            'z_log_var': z_log_var\n",
    "        }\n",
    "\n",
    "    def reparametrization(self, z_mean, z_log_var):\n",
    "        \"\"\" Performs the riparametrization trick\"\"\"\n",
    "\n",
    "        eps = tf.random.normal(shape=(self.latent_dim,), mean=0.0, stddev=1.0)\n",
    "        z = z_mean + tf.math.exp(z_log_var * .5) * eps\n",
    "        # z_cond = tf.concat([z, input_label], axis=1)  # (batch_size, label_dim + latent_dim)\n",
    "\n",
    "        return z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "label_dim = 5\n",
    "image_dim = (1024, 1024, 1)\n",
    "beta=0.6\n",
    "\n",
    "encoder = Encoder(label_dim=label_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(label_dim=label_dim)\n",
    "\n",
    "cvae = ConvCVAE(encoder, decoder, label_dim, latent_dim, image_dim=image_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_input = layers.Input(shape=(1024, 1024, 1))\n",
    "label_input = layers.Input(shape=(5,))\n",
    "\n",
    "outputs = cvae([image_input, label_input])\n",
    "model = tf.keras.Model(inputs=[image_input, label_input], outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model=tf.keras.applications.VGG19(include_top=False,input_shape=(64,64,3))\n",
    "# tf.keras.utils.plot_model(model, to_file='cvae_1.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checkpoint path\n",
    "checkpoint_root = \"./CVAE{}_{}_checkpoint\".format(latent_dim, beta)\n",
    "checkpoint_name = \"model\"\n",
    "save_prefix = os.path.join(checkpoint_root, checkpoint_name)\n",
    "\n",
    "# Define the checkpoint\n",
    "checkpoint = tf.train.Checkpoint(module=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images=np.load('data/saved np/images_no_filters.npy')/255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 90, 1024, 1024, 1)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_recon_errors = []\n",
    "train_latent_losses = []\n",
    "loss = []\n",
    "reconstruct_loss = []\n",
    "latent_loss = []\n",
    "\n",
    "step_index = 0\n",
    "n_batches = int(dataset.train_size / batch_size)\n",
    "n_epochs = 30\n",
    "\n",
    "print(\"Number of epochs: {},  number of batches: {}\".format(n_epochs, n_batches))\n",
    "\n",
    "# Epochs Loop\n",
    "for epoch in range(5):\n",
    "    start_time = time.perf_counter()\n",
    "    dataset.shuffle() # Shuffling\n",
    "\n",
    "    # Train Step Loop\n",
    "    for step_index, inputs in enumerate(dataset):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            model_output = model(inputs, is_train=True)\n",
    "\n",
    "            trainable_variables = model.trainable_variables\n",
    "            grads = tape.gradient(model_output['loss'], trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "            total_loss = model_output['loss'].numpy().mean()\n",
    "            recon_loss = model_output['reconstr_loss'].numpy().mean()\n",
    "            latent_loss = model_output['latent_loss'].numpy().mean()\n",
    "\n",
    "\n",
    "            train_losses.append(total_loss)\n",
    "            train_recon_errors.append(recon_loss)\n",
    "            train_latent_losses.append(latent_loss)\n",
    "\n",
    "            if step_index + 1 == n_batches:\n",
    "                break\n",
    "\n",
    "    loss.append(np.mean(train_losses, 0))\n",
    "    reconstruct_loss.append(np.mean(train_recon_errors, 0))\n",
    "    latent_loss.append(np.mean(train_latent_losses, 0))\n",
    "\n",
    "    exec_time = time.perf_counter() - start_time\n",
    "    print(\"Execution time: %0.3f \\t Epoch %i: loss %0.4f | reconstr loss %0.4f | latent loss %0.4f\"\n",
    "          % (exec_time, epoch, loss[epoch], reconstruct_loss[epoch], latent_loss[epoch]))\n",
    "\n",
    "\n",
    "    # Save progress every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(save_prefix + \"_\" + str(epoch + 1))\n",
    "        print(\"Model saved:\", save_prefix)\n",
    "\n",
    "# Save the final model\n",
    "checkpoint.save(save_prefix)\n",
    "print(\"Model saved:\", save_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}