{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from skimage import transform, metrics\n",
    "from umap import UMAP\n",
    "import datetime\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import io\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "import plotly.express as px\n",
    "\n",
    "from src.utils import GrainLogs\n",
    "from src.nn import RSU7, RSU6, RSU5, RSU4, RSU4F, ConvBlock\n",
    "from src.nn_utils import SaveImageCallback\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, label_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage1 = RSU7(16, 32)\n",
    "        self.pool12 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage2 = RSU6(32, 64)\n",
    "        self.pool23 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage3 = RSU5(64, 128)\n",
    "        self.pool34 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage4 = RSU4(128, 256)\n",
    "        self.pool45 = layers.MaxPool2D((2, 2), 2)\n",
    "        #out_w_h=64\n",
    "\n",
    "        self.stage5 = RSU4F(256, 256)\n",
    "        self.pool56 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Encoder block 1\n",
    "\n",
    "        hx1 = self.stage1(inputs)\n",
    "\n",
    "        hx = self.pool12(hx1)\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        hx5 = self.stage5(hx)\n",
    "        x = self.pool56(hx5)\n",
    "        global_pool = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(global_pool)\n",
    "        x = tf.keras.layers.Dense(256)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(self.latent_dim + self.latent_dim)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x_label = layers.Dense(128)(global_pool)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim, name='encoder_label_output')(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        # return x, x_label\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, label_dim, batch_size=32, out_ch=1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.label_dim = label_dim\n",
    "        self.out_ch = out_ch\n",
    "\n",
    "        self.stage6 = RSU4F(256, 256)\n",
    "        self.stage5d = RSU4F(128, 128)\n",
    "        self.stage4d = RSU4(64, 64)\n",
    "        self.stage3d = RSU5(32, 32)\n",
    "        self.stage2d = RSU6(16, out_ch)\n",
    "        self.stage1d = RSU7(16, out_ch)\n",
    "\n",
    "    def __call__(self, z_inputs):\n",
    "        # Reshape input\n",
    "        # z_image_v, labels = tf.split(z_inputs, axis=1, num_or_size_splits=2)\n",
    "        # z_data = tf.concat(z_inputs, axis=1)\n",
    "        x = layers.Dense(512)(z_inputs)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = layers.Dense(1024)(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = layers.Reshape(target_shape=(32, 32, 1))(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU4F(256, 256)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU4F(128, 128)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU4(64, 64)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU5(32, 32)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU6(16, self.out_ch)(x)\n",
    "\n",
    "        x = activations.sigmoid(x)\n",
    "\n",
    "        # return x, x_label\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = (200,)\n",
    "label_dim = (5,)\n",
    "\n",
    "decoder = Decoder(label_dim=5)\n",
    "z_input = layers.Input(shape=latent_dim)\n",
    "label_input = layers.Input(shape=label_dim)\n",
    "outputs = decoder([z_input, label_input])\n",
    "\n",
    "model = tf.keras.Model(inputs=[z_input, label_input], outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model=tf.keras.applications.VGG19(include_top=False,input_shape=(64,64,3))\n",
    "# tf.keras.utils.plot_model(model, to_file='cvae_1.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = np.load('data/saved np/images_no_filters.npy')\n",
    "\n",
    "grain_names = np.array(\n",
    "    [['Ultra_Co8.jpg'], ['Ultra_Co11.jpg'], ['Ultra_Co6_2.jpg'], ['Ultra_Co15.jpg'], ['Ultra_Co25.jpg']])\n",
    "\n",
    "labels = np.array([[91, 12.1, 1210],\n",
    "                   [78, 8.1, 1180],\n",
    "                   [62, 8.9, 1100],\n",
    "                   [72, 21.6, 990],\n",
    "                   [99, 15.3, 1200]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "\n",
    "labels_dataset = []\n",
    "for i in range(images.shape[0]):\n",
    "    for j in range(images.shape[1]):\n",
    "        labels_dataset.append(labels[i])\n",
    "\n",
    "images_dataset = images.reshape((-1, 1024, 1024, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images, test_images = train_test_split(images_dataset, test_size=0.2, random_state=421)\n",
    "train_labels, test_labels = train_test_split(labels_dataset, test_size=0.2, random_state=421)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checkpoint path\n",
    "checkpoint_root = \"./CVAE{}_{}_checkpoint\".format(latent_dim, beta)\n",
    "checkpoint_name = \"model\"\n",
    "save_prefix = os.path.join(checkpoint_root, checkpoint_name)\n",
    "\n",
    "# Define the checkpoint\n",
    "checkpoint = tf.train.Checkpoint(module=cvae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ConvCVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 label_dim,\n",
    "                 latent_dim,\n",
    "                 beta=1,\n",
    "                 batch_size=2\n",
    "                 ):\n",
    "        super(ConvCVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, label_dim=label_dim)\n",
    "        self.decoder = Decoder(label_dim=label_dim)\n",
    "        self.label_dim = label_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(self.batch_size, 100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=False)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "\n",
    "        eps = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_loss(model, x):\n",
    "    z_mean, z_log_var = model.encode(x)\n",
    "    z = model.reparameterize(z_mean, z_log_var)\n",
    "    logits = model.decode(z)\n",
    "    rec_loss = tf.cast(tf.reduce_mean(tf.keras.losses.mean_squared_error(logits, x))*np.prod((1024,1024)), tf.float32)\n",
    "    # rec_loss = tf.cast(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=x), 1), tf.float32)\n",
    "    latent_loss = tf.cast(-0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1),\n",
    "                          tf.float32)\n",
    "\n",
    "    total_loss = rec_loss + beta * latent_loss\n",
    "    # print(\n",
    "    #     f'total loss {total_loss}, reconstr_loss {rec_loss}, latent_loss {latent_loss}')\n",
    "\n",
    "    return total_loss, rec_loss, latent_loss\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        total_loss, rec_loss, latent_loss = compute_loss(model, x)\n",
    "\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return total_loss, rec_loss, latent_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    prediction = model.sample(z).numpy()[0] * 255\n",
    "    io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_mean, z_log_var = model.encode(np.expand_dims(train_images[0], axis=0))\n",
    "z = model.reparameterize(z_mean, z_log_var)\n",
    "logits = model.decode(z)\n",
    "logits.numpy()[0].astype(np.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(logits[0] * 255)\n",
    "plt.savefig('test.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "io.imsave('test.png', logits[0] * 255)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 23, np.expand_dims(train_images[0], axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def printProgressBar(epoch, iteration, total, prefix='', suffix='', decimals=1, length=100, fill='█', printEnd=\"\\r\",\n",
    "                     eta=None, loss=None, train_type='train'):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(\n",
    "        f'\\r{prefix} |{bar}| {percent}% {suffix} ETA:{eta} s epoch={epoch}: ELBO={str(np.round(loss[0], 4))},rec_loss={str(np.round(loss[1], 4))} lat_loss={str(round(loss[2], 4))}',\n",
    "        end=printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 512\n",
    "label_dim = 3\n",
    "\n",
    "model = ConvCVAE(label_dim, latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |-| 41.7% Complete ETA:None s epoch=10: ELBO=116862.0,rec_loss=156969.44 lat_loss=0.0047\r"
     ]
    }
   ],
   "source": [
    "# generate_and_save_images(model, 0, test_sample)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3,centered=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "batch_size = 2\n",
    "beta = 1\n",
    "\n",
    "n_batches = train_images.shape[0] // batch_size\n",
    "n_batches_test = test_images.shape[0] // batch_size\n",
    "model.batch_size = batch_size\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images.astype(np.float32)).batch(batch_size).as_numpy_iterator()\n",
    "    test_images_dataset = tf.data.Dataset.from_tensor_slices(test_images.astype(np.float32)).batch(batch_size).as_numpy_iterator()\n",
    "\n",
    "    start_time = time.time()\n",
    "    total_loss = []\n",
    "    total_rec_loss = []\n",
    "    total_latent_loss = []\n",
    "\n",
    "    printProgressBar(epoch, 0, n_batches, eta=None, loss=[0, 0, 0], prefix='Progress:', suffix='Complete',\n",
    "                     train_type='train', length=1)\n",
    "    for i, train_x in enumerate(range(n_batches)):\n",
    "        # print(f'epoch={epoch} batch num={i}/{n_batches}')\n",
    "\n",
    "        loss, rec_loss, latent_loss = train_step(model, train_images_dataset.next(), optimizer)\n",
    "        total_loss.append(loss)\n",
    "        total_rec_loss.append(rec_loss)\n",
    "        total_latent_loss.append(latent_loss)\n",
    "        printProgressBar(epoch, i, n_batches, eta=None, prefix='Progress:', suffix='Complete', train_type='train',\n",
    "                         loss=[np.mean(total_loss), np.mean(rec_loss), np.mean(total_latent_loss)], length=1)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for i, test_x in enumerate(range(n_batches_test)):\n",
    "        loss(compute_loss(model,test_images_dataset.next())[0])\n",
    "    elbo = loss.result()\n",
    "    # display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "          .format(epoch, elbo, end_time - start_time))\n",
    "    test_sample = test_images[np.random.randint(0, test_images.shape[0])]\n",
    "    generate_and_save_images(model, epoch, np.expand_dims(test_sample, axis=0).astype(np.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(1024, input_shape=(400,)))\n",
    "model.add(layers.Reshape((32, 32, 1)))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4F(256, 512))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4F(128, 256))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4(64, 128))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4(32, 64))\n",
    "model.add(layers.Conv2DTranspose(16, kernel_size=(2, 2), strides=(2, 2)))\n",
    "# model.add(RSU4(16, 1))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}