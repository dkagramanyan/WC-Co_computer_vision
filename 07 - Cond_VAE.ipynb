{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from skimage import transform, metrics\n",
    "from umap import UMAP\n",
    "import datetime\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import io\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "import plotly.express as px\n",
    "\n",
    "from src.nn import RSU7, RSU6, RSU5, RSU4, RSU4F, ConvBlock\n",
    "from src.nn_utils import SaveImageCallback\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, label_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage1 = RSU7(16, 64)\n",
    "        self.pool12 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage2 = RSU6(32, 64)\n",
    "        self.pool23 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage3 = RSU5(64, 128)\n",
    "        self.pool34 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage4 = RSU4(128, 256)\n",
    "        self.pool45 = layers.MaxPool2D((2, 2), 2)\n",
    "        #out_w_h=64\n",
    "\n",
    "        self.stage5 = RSU4F(256, 512)\n",
    "        self.pool56 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Encoder block 1\n",
    "\n",
    "        hx1 = self.stage1(inputs)\n",
    "\n",
    "        hx = self.pool12(hx1)\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        hx5 = self.stage5(hx)\n",
    "        x = self.pool56(hx5)\n",
    "        global_pool = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(global_pool)\n",
    "        x = tf.keras.layers.Dense(256)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(self.latent_dim + self.latent_dim)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x_label = layers.Dense(128)(global_pool)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim, name='encoder_label_output')(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        # return x, x_label\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = (200,)\n",
    "label_dim = (5,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_dim=200, label_dim=5)\n",
    "image_input = layers.Input(shape=(1024, 1024, 1))\n",
    "label_input = layers.Input(shape=(5,))\n",
    "\n",
    "outputs = encoder([image_input, label_input])\n",
    "model = tf.keras.Model(inputs=[image_input, label_input], outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, label_dim, batch_size=32, out_ch=1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage6 = RSU4F(256, 512)\n",
    "        self.stage5d = RSU4F(128, 256)\n",
    "        self.stage4d = RSU4(64, 128)\n",
    "        self.stage3d = RSU5(32, 64)\n",
    "        self.stage2d = RSU6(16, 64)\n",
    "        self.stage1d = RSU7(16, out_ch)\n",
    "\n",
    "        self.upsample_1 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_2 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_3 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_4 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_5 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_6 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear', name='rec_image_output')\n",
    "\n",
    "    def __call__(self, z_inputs):\n",
    "        # Reshape input\n",
    "        # z_image_v, labels = tf.split(z_inputs, axis=1, num_or_size_splits=2)\n",
    "        z_data = tf.concat(z_inputs, axis=1)\n",
    "        x = layers.Dense(256)(z_data)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = layers.Reshape(target_shape=(16, 16, 1))(x)\n",
    "\n",
    "        hx6 = self.stage6(x)\n",
    "        hx6up = self.upsample_6(hx6)\n",
    "\n",
    "        max_pool = layers.GlobalAveragePooling2D()(hx6up)\n",
    "        x_label = layers.Dense(128)(max_pool)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim, name='rec_label_output')(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        hx5d = self.stage5d(hx6up)\n",
    "        hx5dup = self.upsample_5(hx5d)\n",
    "\n",
    "        hx4d = self.stage4d(hx5dup)\n",
    "        hx4dup = self.upsample_4(hx4d)\n",
    "\n",
    "        hx3d = self.stage3d(hx4dup)\n",
    "        hx3dup = self.upsample_3(hx3d)\n",
    "\n",
    "        hx2d = self.stage2d(hx3dup)\n",
    "        hx2dup = self.upsample_2(hx2d)\n",
    "\n",
    "        hx1d = self.stage1d(hx2dup)\n",
    "        x = self.upsample_1(hx1d)\n",
    "\n",
    "        x = activations.sigmoid(x)\n",
    "\n",
    "        # return x, x_label\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = (200,)\n",
    "label_dim = (5,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoder = Decoder(label_dim=5)\n",
    "z_input = layers.Input(shape=latent_dim)\n",
    "label_input = layers.Input(shape=label_dim)\n",
    "outputs = decoder([z_input, label_input])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[z_input, label_input], outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ConvCVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 label_dim,\n",
    "                 latent_dim,\n",
    "                 image_dim,\n",
    "                 beta=1,\n",
    "                 batch_size=32\n",
    "                 ):\n",
    "        super(ConvCVAE, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.label_dim = label_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.image_dim = image_dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        input_img, input_label = inputs\n",
    "\n",
    "        # z_latent, enc_labels = self.encoder(inputs=(input_img, input_label))\n",
    "        z_latent = self.encoder(inputs=(input_img, input_label))\n",
    "        z_mean, z_log_var = tf.split(z_latent, num_or_size_splits=2, axis=1)\n",
    "\n",
    "        z_cond = self.reparametrization(z_mean, z_log_var)\n",
    "\n",
    "        # logits, dec_labels = self.decoder((z_cond, input_label))\n",
    "        recon_img = self.decoder(z_cond)\n",
    "\n",
    "\n",
    "\n",
    "        # return recon_img,enc_labels,dec_labels\n",
    "\n",
    "        # Loss computation #\n",
    "        latent_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var),\n",
    "                                            axis=-1)  # KL divergence\n",
    "\n",
    "        # очень странная метрика для изображений\n",
    "        # np.prod((64, 64)) *\n",
    "        # print(tf.keras.backend.flatten(input_img))\n",
    "        reconstr_loss = tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "                                            tf.keras.backend.flatten(\n",
    "                                                recon_img))\n",
    "        # enc_label_loss = tf.losses.MSE(tf.keras.backend.flatten(input_label), tf.keras.backend.flatten(enc_labels)\n",
    "        #                                )\n",
    "        # dec_label_loss = tf.losses.MSE(tf.keras.backend.flatten(input_label), tf.keras.backend.flatten(dec_labels)\n",
    "        #                                )\n",
    "        # loss = reconstr_loss + enc_label_loss + dec_label_loss + self.beta * latent_loss  # weighted ELBO loss\n",
    "        loss = reconstr_loss + self.beta * latent_loss  # weighted ELBO loss\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        return {\n",
    "            'recon_img': recon_img,\n",
    "            'latent_loss': latent_loss,\n",
    "            'reconstr_loss': reconstr_loss,\n",
    "            # 'enc_label_loss': enc_label_loss,\n",
    "            # 'dec_label_loss': dec_label_loss,\n",
    "            'loss': loss,\n",
    "            'z_mean': z_mean,\n",
    "            'z_log_var': z_log_var\n",
    "        }\n",
    "\n",
    "    def reparametrization(self, z_mean, z_log_var):\n",
    "        \"\"\" Performs the riparametrization trick\"\"\"\n",
    "\n",
    "        eps = tf.random.normal(shape=(z_mean.shape[0], self.latent_dim), mean=0.0, stddev=1.0)\n",
    "        z = z_mean + tf.math.exp(z_log_var * .5) * eps\n",
    "        # z_cond = tf.concat([z, input_label], axis=1)  # (batch_size, label_dim + latent_dim)\n",
    "\n",
    "        return z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "label_dim = 5\n",
    "image_dim = (1024, 1024, 1)\n",
    "beta = 0.6\n",
    "\n",
    "encoder = Encoder(label_dim=label_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(label_dim=label_dim)\n",
    "\n",
    "cvae = ConvCVAE(encoder, decoder, label_dim, latent_dim, image_dim=image_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_input = layers.Input(shape=(1024, 1024, 1))\n",
    "label_input = layers.Input(shape=(5,))\n",
    "\n",
    "outputs = cvae([image_input, label_input])\n",
    "model = tf.keras.Model(inputs=[image_input, label_input], outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model=tf.keras.applications.VGG19(include_top=False,input_shape=(64,64,3))\n",
    "# tf.keras.utils.plot_model(model, to_file='cvae_1.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = np.load('data/saved np/images_no_filters.npy') / 255\n",
    "\n",
    "grain_names = np.array(\n",
    "    [['Ultra_Co8.jpg'], ['Ultra_Co11.jpg'], ['Ultra_Co6_2.jpg'], ['Ultra_Co15.jpg'], ['Ultra_Co25.jpg']])\n",
    "\n",
    "labels = np.array([[91, 12.1, 1210],\n",
    "                   [78, 8.1, 1180],\n",
    "                   [62, 8.9, 1100],\n",
    "                   [72, 21.6, 990],\n",
    "                   [99, 15.3, 1200]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "\n",
    "labels_dataset = []\n",
    "for i in range(images.shape[0]):\n",
    "    for j in range(images.shape[1]):\n",
    "        labels_dataset.append(labels[i])\n",
    "\n",
    "images_dataset = images.reshape((-1, 1024, 1024, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images, test_images = train_test_split(images_dataset, test_size=0.2, random_state=421)\n",
    "train_labels, test_labels = train_test_split(labels_dataset, test_size=0.2, random_state=421)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "label_dim = 3\n",
    "image_dim = (1024, 1024, 1)\n",
    "beta = 1\n",
    "batch_size = 2\n",
    "\n",
    "encoder = Encoder(label_dim=label_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(label_dim=label_dim)\n",
    "\n",
    "cvae = ConvCVAE(encoder, decoder, label_dim, latent_dim, image_dim=image_dim, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checkpoint path\n",
    "checkpoint_root = \"./CVAE{}_{}_checkpoint\".format(latent_dim, beta)\n",
    "checkpoint_name = \"model\"\n",
    "save_prefix = os.path.join(checkpoint_root, checkpoint_name)\n",
    "\n",
    "# Define the checkpoint\n",
    "checkpoint = tf.train.Checkpoint(module=cvae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_recon_errors = []\n",
    "train_latent_losses = []\n",
    "loss = []\n",
    "reconstruct_loss = []\n",
    "latent_loss = []\n",
    "\n",
    "step_index = 0\n",
    "n_batches = int(train_images.shape[0] / batch_size)\n",
    "n_epochs = 30\n",
    "\n",
    "train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(batch_size).as_numpy_iterator()\n",
    "train_labels_dataset = tf.data.Dataset.from_tensor_slices(train_labels).batch(batch_size).as_numpy_iterator()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "print(\"Number of epochs: {},  number of batches: {}\".format(n_epochs, n_batches))\n",
    "# Epochs Loop\n",
    "for epoch in range(5):\n",
    "    start_time = time.perf_counter()\n",
    "    train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(batch_size).as_numpy_iterator()\n",
    "    train_labels_dataset = tf.data.Dataset.from_tensor_slices(train_labels).batch(batch_size).as_numpy_iterator()\n",
    "    # Train Step Loop\n",
    "    for step_index in range(n_batches):\n",
    "        with tf.GradientTape() as tape:\n",
    "            input_images = train_images_dataset.next()\n",
    "            input_labels = train_labels_dataset.next()\n",
    "\n",
    "            model_output = cvae((input_images, input_labels))\n",
    "            trainable_variables = cvae.trainable_variables\n",
    "            grads = tape.gradient(model_output['loss'], trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "            total_loss = model_output['loss'].numpy().mean()\n",
    "            recon_loss = model_output['reconstr_loss'].numpy().mean()\n",
    "            latent_loss_1 = model_output['latent_loss'].numpy().mean()\n",
    "            # enc_label_loss = model_output['enc_label_loss'].numpy().mean()\n",
    "            enc_label_loss = None\n",
    "            # dec_label_loss = model_output['dec_label_loss'].numpy().mean()\n",
    "            dec_label_loss = None\n",
    "\n",
    "            total_loss_pr = np.round(total_loss, 3)\n",
    "            recon_loss_pr = np.round(recon_loss, 3)\n",
    "            latent_loss_1_pr = np.round(latent_loss_1, 3)\n",
    "\n",
    "            train_losses.append(total_loss)\n",
    "            train_recon_errors.append(recon_loss)\n",
    "            train_latent_losses.append(latent_loss_1)\n",
    "            print('------------------------')\n",
    "            print(\n",
    "                f'iter={step_index}/{n_batches} total loss {total_loss_pr}, reconstr_loss {recon_loss_pr}, latent_loss {latent_loss_1_pr}, enc_label_loss={enc_label_loss},dec_label_loss={dec_label_loss}')\n",
    "\n",
    "            # if step_index + 1 == n_batches:\n",
    "            #     break\n",
    "\n",
    "    loss.append(np.mean(train_losses, 0))\n",
    "    reconstruct_loss.append(np.mean(train_recon_errors, 0))\n",
    "    latent_loss.append(np.mean(train_latent_losses, 0))\n",
    "\n",
    "    exec_time = time.perf_counter() - start_time\n",
    "    print(\"Execution time: %0.3f \\t Epoch %i: loss %0.4f | reconstr loss %0.4f | latent loss %0.4f\"\n",
    "          % (exec_time, epoch, loss[epoch], reconstruct_loss[epoch], latent_loss[epoch]))\n",
    "\n",
    "    # Save progress every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(save_prefix + \"_\" + str(epoch + 1))\n",
    "        print(\"Model saved:\", save_prefix)\n",
    "\n",
    "# Save the final model\n",
    "checkpoint.save(save_prefix)\n",
    "print(\"Model saved:\", save_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ConvCVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 label_dim,\n",
    "                 latent_dim,\n",
    "                 beta=1,\n",
    "                 batch_size=2\n",
    "                 ):\n",
    "        super(ConvCVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, label_dim=label_dim)\n",
    "        self.decoder = Decoder(label_dim=label_dim)\n",
    "        self.label_dim = label_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    # @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(self.batch_size,100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=False)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=(self.batch_size,mean.shape[0]))\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_loss(model, x):\n",
    "    z_mean, z_log_var = model.encode(x)\n",
    "    z = model.reparameterize(z_mean, z_log_var)\n",
    "    logits = model.decode(z)\n",
    "    rec_loss = tf.cast(tf.reduce_sum(tf.keras.losses.mean_squared_error(logits, x)),tf.float32)\n",
    "\n",
    "\n",
    "    latent_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "\n",
    "    total_loss = rec_loss + beta*latent_loss\n",
    "    print(\n",
    "        f'total loss {total_loss}, reconstr_loss {rec_loss}, latent_loss {latent_loss}')\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_val = compute_loss(model, x)\n",
    "\n",
    "    gradients = tape.gradient(loss_val, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss_val\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_mean, z_log_var = model.encode(np.expand_dims(train_images[0],axis=0))\n",
    "z = model.reparameterize(z_mean, z_log_var)\n",
    "logits = model.decode(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    prediction = model.sample(z).numpy().astype(np.uint8)[0,:,:]*255\n",
    "    io.imsave('image_at_epoch_{:04d}.png'.format(epoch),prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 200\n",
    "label_dim = 3\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "\n",
    "\n",
    "model = ConvCVAE(label_dim, latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate_and_save_images(model, 0, test_sample)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\n",
    "batch_size=1\n",
    "beta=1\n",
    "\n",
    "n_batches=train_images.shape[0]//batch_size\n",
    "model.batch_size=batch_size\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(batch_size).as_numpy_iterator()\n",
    "\n",
    "    start_time = time.time()\n",
    "    loss =[]\n",
    "    for i, train_x in enumerate(range(n_batches)):\n",
    "\n",
    "        print(f'epoch={epoch} batch num={i}/{n_batches}')\n",
    "        loss.append(train_step(model, train_images_dataset.next(), optimizer))\n",
    "\n",
    "    print('train ELBO loss ',np.mean(loss))\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_images.astype(np.float32):\n",
    "        loss(compute_loss(model, np.expand_dims(test_x, axis=0)))\n",
    "    elbo = loss.result()\n",
    "    # display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "          .format(epoch, elbo, end_time - start_time))\n",
    "    test_sample=test_images[np.random.randint(0,test_images.shape[0])]\n",
    "    generate_and_save_images(model, epoch, np.expand_dims(test_sample,axis=0).astype(np.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "label_dim = 3\n",
    "image_dim = (1024, 1024, 1)\n",
    "beta = 0.8\n",
    "batch_size = 2\n",
    "\n",
    "encoder = Encoder(latent_dim=latent_dim, label_dim=label_dim)\n",
    "# image_input = layers.Input(shape=(1024, 1024, 1))\n",
    "# label_input = layers.Input(shape=(latent_dim,))\n",
    "#\n",
    "# outputs = encoder([image_input,label_input])\n",
    "# encoder = tf.keras.Model(inputs=[image_input, label_input], outputs=outputs)\n",
    "\n",
    "\n",
    "decoder = Decoder(label_dim=label_dim)\n",
    "\n",
    "cvae = ConvCVAE(encoder, decoder, label_dim, latent_dim, image_dim=image_dim, batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_recon_errors = []\n",
    "train_latent_losses = []\n",
    "loss = []\n",
    "reconstruct_loss = []\n",
    "total_latent_loss = []\n",
    "\n",
    "step_index = 0\n",
    "n_batches = int(train_images.shape[0] / batch_size)\n",
    "n_epochs = 30\n",
    "\n",
    "train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(batch_size).as_numpy_iterator()\n",
    "train_labels_dataset = tf.data.Dataset.from_tensor_slices(train_labels).batch(batch_size).as_numpy_iterator()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "print(\"Number of epochs: {},  number of batches: {}\".format(n_epochs, n_batches))\n",
    "# Epochs Loop\n",
    "for epoch in range(5):\n",
    "    start_time = time.perf_counter()\n",
    "    train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(batch_size).as_numpy_iterator()\n",
    "    train_labels_dataset = tf.data.Dataset.from_tensor_slices(train_labels).batch(batch_size).as_numpy_iterator()\n",
    "    # Train Step Loop\n",
    "    for step_index in range(n_batches):\n",
    "        with tf.GradientTape() as tape:\n",
    "            input_images = train_images_dataset.next()\n",
    "            input_labels = train_labels_dataset.next()\n",
    "\n",
    "            z_latent = encoder(inputs=(input_images, input_labels))\n",
    "\n",
    "            z_mean, z_log_var = tf.split(z_latent, num_or_size_splits=2, axis=1)\n",
    "            z_rep = reparametrization(z_mean, z_log_var, latent_dim)\n",
    "\n",
    "            logits = decoder(z_rep)\n",
    "            recon_images = tf.nn.sigmoid(logits)\n",
    "\n",
    "            latent_loss = - 0.5 * (tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var),\n",
    "                                                 axis=-1))  # KL divergence\n",
    "\n",
    "            latent_loss = latent_loss.numpy().mean()\n",
    "\n",
    "            reconstr_loss = tf.keras.losses.MSE(tf.keras.backend.flatten(input_images),\n",
    "                                                tf.keras.backend.flatten(\n",
    "                                                    recon_images))\n",
    "\n",
    "            train_loss = reconstr_loss + beta * latent_loss  # weighted ELBO loss\n",
    "            train_loss = tf.reduce_mean(train_loss)\n",
    "\n",
    "            trainable_variables = cvae.trainable_variables\n",
    "            grads = tape.gradient(train_loss, trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_recon_errors.append(reconstr_loss)\n",
    "            train_latent_losses.append(latent_loss)\n",
    "            print('------------------------')\n",
    "            print(\n",
    "                f'iter={step_index}/{n_batches} total loss {train_loss}, reconstr_loss {reconstr_loss}, latent_loss {latent_loss}')\n",
    "\n",
    "            # if step_index + 1 == n_batches:\n",
    "            #     break\n",
    "    loss.append(np.mean(train_losses, 0))\n",
    "    reconstruct_loss.append(np.mean(train_recon_errors, 0))\n",
    "    total_latent_loss.append(np.mean(train_latent_losses, 0))\n",
    "\n",
    "    exec_time = time.perf_counter() - start_time\n",
    "    print(\"Execution time: %0.3f \\t Epoch %i: loss %0.4f | reconstr loss %0.4f | latent loss %0.4f\"\n",
    "          % (exec_time, epoch, loss[epoch], reconstruct_loss[epoch], total_latent_loss[epoch]))\n",
    "\n",
    "    # Save progress every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(save_prefix + \"_\" + str(epoch + 1))\n",
    "        print(\"Model saved:\", save_prefix)\n",
    "\n",
    "# Save the final model\n",
    "checkpoint.save(save_prefix)\n",
    "print(\"Model saved:\", save_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}