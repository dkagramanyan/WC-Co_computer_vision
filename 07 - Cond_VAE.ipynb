{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from skimage import transform, metrics\n",
    "from umap import UMAP\n",
    "import datetime\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import io\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "import plotly.express as px\n",
    "\n",
    "from src.nn import ConvCVAE, Decoder, Encoder\n",
    "from src.nn import RSU7, RSU6, RSU5, RSU4, RSU4F, ConvBlock\n",
    "from src.nn_utils import SaveImageCallback\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.prod((64, 64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_step(data, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model_output = model(data, is_train=True)\n",
    "\n",
    "    trainable_variables = model.trainable_variables\n",
    "    grads = tape.gradient(model_output['loss'], trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "    total_loss = model_output['loss'].numpy().mean()\n",
    "    recon_loss = model_output['reconstr_loss'].numpy().mean()\n",
    "    latent_loss = model_output['latent_loss'].numpy().mean()\n",
    "\n",
    "    return total_loss, recon_loss, latent_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_dim = 40\n",
    "image_dim = [64, 64, 3]\n",
    "latent_dim = 128\n",
    "beta = 0.65\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "train_size = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "# Model\n",
    "encoder = Encoder(latent_dim)\n",
    "decoder = Decoder()\n",
    "model = ConvCVAE(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    label_dim=label_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    beta=beta,\n",
    "    image_dim=image_dim)\n",
    "\n",
    "# Optiizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_shape = (1024, 1024, 1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=image_shape)\n",
    "encoder = Encoder(latent_dim)\n",
    "out = encoder(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, label_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage1 = RSU7(16, 64)\n",
    "        self.pool12 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage2 = RSU6(32, 64)\n",
    "        self.pool23 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage3 = RSU5(64, 128)\n",
    "        self.pool34 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage4 = RSU4(128, 256)\n",
    "        self.pool45 = layers.MaxPool2D((2, 2), 2)\n",
    "        #out_w_h=64\n",
    "\n",
    "        self.stage5 = RSU4F(256, 512)\n",
    "        self.pool56 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Encoder block 1\n",
    "\n",
    "        input_image,input_label=inputs[0],inputs[1]\n",
    "\n",
    "        x_label = layers.Dense(128)(input_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim)(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        hx1 = self.stage1(input_image)\n",
    "\n",
    "        hx = self.pool12(hx1)\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        hx5 = self.stage5(hx)\n",
    "        x = self.pool56(hx5)\n",
    "        x=layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(512)(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(self.latent_dim * 2)(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "\n",
    "        return x,x_label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = (200,)\n",
    "label_dim = (5,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder=Encoder(latent_dim=200,label_dim=5)\n",
    "image_input=layers.Input(shape=(1024,1024,1))\n",
    "label_input=layers.Input(shape=(5,))\n",
    "\n",
    "outputs=encoder([image_input,label_input])\n",
    "model=tf.keras.Model(inputs=[image_input,label_input],outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, label_dim, batch_size=32, out_ch=1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.label_dim = label_dim\n",
    "        self.dense = tf.keras.layers.Dense(4 * 4 * self.batch_size * 8)\n",
    "        self.reshape = tf.keras.layers.Reshape(target_shape=(4, 4, self.batch_size * 8))\n",
    "\n",
    "        self.stage6 = RSU4F(256, 512)\n",
    "        self.stage5d = RSU4F(256, 512)\n",
    "        self.stage4d = RSU4(128, 256)\n",
    "        self.stage3d = RSU5(64, 128)\n",
    "        self.stage2d = RSU6(32, 64)\n",
    "        self.stage1d = RSU7(16, out_ch)\n",
    "\n",
    "        self.upsample_1 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_2 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_3 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_4 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_5 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.upsample_6 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "\n",
    "    def __call__(self, z_inputs):\n",
    "        # Reshape input\n",
    "        # z_image_v, labels = tf.split(z_inputs, axis=1, num_or_size_splits=2)\n",
    "        z_data = tf.concat(z_inputs, axis=1)\n",
    "        print(z_data)\n",
    "        x = layers.Dense(256)(z_data)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x_label = layers.Dense(128)(x)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim)(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        x = layers.Reshape(target_shape=(16,16,1))(x)\n",
    "\n",
    "\n",
    "        hx6 = self.stage6(x)\n",
    "        hx6up = self.upsample_6(hx6)\n",
    "\n",
    "        hx5d = self.stage5d(hx6up)\n",
    "        hx5dup = self.upsample_5(hx5d)\n",
    "\n",
    "        hx4d = self.stage4d(hx5dup)\n",
    "        hx4dup = self.upsample_4(hx4d)\n",
    "\n",
    "\n",
    "        hx3d = self.stage3d(hx4dup)\n",
    "        hx3dup = self.upsample_3(hx3d)\n",
    "\n",
    "        hx2d = self.stage2d(hx3dup)\n",
    "        hx2dup = self.upsample_2(hx2d)\n",
    "\n",
    "        hx1d = self.stage1d(hx2dup)\n",
    "        x = self.upsample_1(hx1d)\n",
    "\n",
    "        x = activations.sigmoid(x)\n",
    "\n",
    "        return x, x_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim=(200,)\n",
    "label_dim=(5,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoder=Decoder(label_dim=5)\n",
    "z_input=layers.Input(shape=latent_dim)\n",
    "label_input=layers.Input(shape=label_dim)\n",
    "outputs=decoder([z_input,label_input])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model=tf.keras.Model(inputs=[z_input,label_input],outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ConvCVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 label_dim,\n",
    "                 latent_dim,\n",
    "                 beta=1,\n",
    "                 image_dim=(64, 64, 3)):\n",
    "        super(ConvCVAE, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.label_dim = label_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.image_dim = image_dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        input_img, input_label, conditional_input = self.conditional_input(inputs)\n",
    "\n",
    "        z_mean, z_log_var = tf.split(self.encoder(conditional_input), num_or_size_splits=2, axis=1)\n",
    "        z_cond = self.reparametrization(z_mean, z_log_var, input_label)\n",
    "        logits = self.decoder(z_cond)\n",
    "\n",
    "        recon_img = tf.nn.sigmoid(logits)\n",
    "\n",
    "        # Loss computation #\n",
    "        latent_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var),\n",
    "                                            axis=-1)  # KL divergence\n",
    "\n",
    "        # очень странная метрика для изображений\n",
    "        reconstr_loss = np.prod((64, 64)) * tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(input_img),\n",
    "                                                                                tf.keras.backend.flatten(\n",
    "                                                                                    recon_img))  # over weighted MSE\n",
    "        loss = reconstr_loss + self.beta * latent_loss  # weighted ELBO loss\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        return {\n",
    "            'recon_img': recon_img,\n",
    "            'latent_loss': latent_loss,\n",
    "            'reconstr_loss': reconstr_loss,\n",
    "            'loss': loss,\n",
    "            'z_mean': z_mean,\n",
    "            'z_log_var': z_log_var\n",
    "        }\n",
    "\n",
    "    def conditional_input(self, inputs):\n",
    "        \"\"\" Builds the conditional input and returns the original input images, their labels and the conditional input.\"\"\"\n",
    "\n",
    "        input_img = tf.keras.layers.InputLayer(input_shape=self.image_dim, dtype='float32')(inputs[0])\n",
    "        input_label = tf.keras.layers.InputLayer(input_shape=(self.label_dim,), dtype='float32')(inputs[1])\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, self.label_dim])  # batch_size, 1, 1, label_size\n",
    "        ones = tf.ones([inputs[0].shape[0]] + self.image_dim[0:-1] + [self.label_dim])  # batch_size, 64, 64, label_size\n",
    "        labels = ones * labels  # batch_size, 64, 64, label_size\n",
    "        conditional_input = tf.keras.layers.InputLayer(\n",
    "            input_shape=(self.image_dim[0], self.image_dim[1], self.image_dim[2] + self.label_dim), dtype='float32')(\n",
    "            tf.concat([inputs[0], labels], axis=3))\n",
    "\n",
    "        return input_img, input_label, conditional_input\n",
    "\n",
    "    def reparametrization(self, z_mean, z_log_var, input_label):\n",
    "        \"\"\" Performs the riparametrization trick\"\"\"\n",
    "\n",
    "        eps = tf.random.normal(shape=(input_label.shape[0], self.latent_dim), mean=0.0, stddev=1.0)\n",
    "        z = z_mean + tf.math.exp(z_log_var * .5) * eps\n",
    "        z_cond = tf.concat([z, input_label], axis=1)  # (batch_size, label_dim + latent_dim)\n",
    "\n",
    "        return z_cond"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}