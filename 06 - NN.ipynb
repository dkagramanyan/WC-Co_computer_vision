{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import grainPreprocess\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#all_images=grainPreprocess.read_preprocess_data('data/dataset',images_num_per_class=150,preprocess=False,save=True,save_name='all_images_no_preprocess.npy',resize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_images=np.load('data/saved np/all_images_no_preprocess.npy',allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_images_rgb=[]\n",
    "for i,images_list in enumerate(all_images):\n",
    "    for image_gray in images_list:\n",
    "        tf_image=tf.expand_dims(image_gray/255,2)\n",
    "        tf_rgb=tf.image.grayscale_to_rgb(tf_image)\n",
    "        tf_preproc=tf.image.resize(tf_rgb,(1024,1024))\n",
    "        all_images_rgb.append(tf_preproc)\n",
    "\n",
    "all_images_rgb=np.array(all_images_rgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_shape=(1024,1024,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoder=tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, input_tensor=None,weights=None,\n",
    "     pooling='max',input_shape=image_shape\n",
    ")\n",
    "\n",
    "encoder=tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "    include_top=False, input_tensor=None,weights=None,\n",
    "    pooling=True,input_shape=(32,32,2)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[keras autoencoder](https://blog.keras.io/building-autoencoders-in-keras.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = tf.keras.Input(shape=image_shape)\n",
    "\n",
    "x=decoder(input_img)\n",
    "x=tf.keras.layers.Reshape((32,32,2))(x)\n",
    "\n",
    "x = encoder(x)\n",
    "x=tf.keras.layers.Conv2DTranspose(32,(3,3),(4,4))(x)\n",
    "x=tf.keras.layers.Conv2DTranspose(32,(3,3),(4,4))(x)\n",
    "x=tf.keras.layers.Conv2DTranspose(32,(3,3),(4,4))(x)\n",
    "x=tf.keras.layers.Conv2D(32,(1,1),(1,1))(x)\n",
    "x=tf.keras.activations.relu(x)\n",
    "x=tf.keras.layers.Conv2DTranspose(32,(3,3),(4,4))(x)\n",
    "x=tf.keras.layers.Conv2DTranspose(3,(3,3),(4,4))(x)\n",
    "x=tf.keras.layers.Conv2D(3,(1,1),(1,1))(x)\n",
    "x=tf.keras.activations.tanh(x)\n",
    "\n",
    "\n",
    "\n",
    "x=tf.keras.layers.Reshape(image_shape)(x)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = tf.keras.Model(input_img, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(  all_images_rgb,all_images_rgb, test_size=0.2, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='MSE',metrics=['MAE'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history=autoencoder.fit(x_train, y_train,\n",
    "                epochs=15,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf2",
   "language": "python",
   "display_name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}