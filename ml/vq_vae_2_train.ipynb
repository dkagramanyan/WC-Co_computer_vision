{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T20:47:35.874424600Z",
     "start_time": "2023-10-10T20:47:29.834572300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from pt_utils import  Embeddings, Trainer, VQVAE, data_sampler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T20:47:37.922469300Z",
     "start_time": "2023-10-10T20:47:37.876591500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15df0c24410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 51\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T21:23:15.387589100Z",
     "start_time": "2023-10-10T21:23:15.308919300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model =    VQVAE(in_channel=3,\n",
    "           channel=128,\n",
    "           n_res_block=6,\n",
    "           n_res_channel=32,\n",
    "           embed_dim=2,\n",
    "           n_embed=8192,\n",
    "           decay=0.99).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# summary(model, input_size=(3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T21:23:18.645361300Z",
     "start_time": "2023-10-10T21:23:18.554540700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_path = '../data/dataset_512/'\n",
    "# dataset_path = '../datasets/bc_right_sub_left_minmax_4x_360'\n",
    "# dataset_path = '../datasets/bc_left_4x_360'\n",
    "# dataset_path = '../datasets/original/o_bc_left_9x_512_360'\n",
    "dataset_path = '../datasets/original/o_bc_left_9x_512_360'\n",
    "\n",
    "resize_shape = (512, 512)\n",
    "# resize_shape = (1024, 1024)\n",
    "\n",
    "n_gpu = 1\n",
    "batch_size = 4\n",
    "val_split = 0.15\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # transforms.Resize(resize_shape),\n",
    "        # transforms.CenterCrop(resize_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "train_dataset_len = int(len(dataset) * (1 - val_split))\n",
    "test_dataset_len = len(dataset) - train_dataset_len\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_dataset_len, test_dataset_len],\n",
    "                                                            generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "train_sampler = data_sampler(train_dataset, shuffle=True, distributed=False)\n",
    "test_sampler = data_sampler(test_dataset, shuffle=True, distributed=False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size // n_gpu, sampler=train_sampler, num_workers=2\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size // n_gpu, sampler=test_sampler, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_file = 'data/logs/emb_dim_1_n_embed_8192_bc_left_sub_right_minmax_4x_360/vqvae_001_train_0.04914_test_0.04206.pt'\n",
    "model_file = 'data/logs/emb_dim_1_n_embed_8192_bc_right_sub_left_minmax_4x_360/vqvae_003_train_0.04287_test_0.04129.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(model_file, map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T21:39:43.538277400Z",
     "start_time": "2023-10-10T21:23:26.983667600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1; loss: 0.02124; mse: 0.02843; latent: 0.000; avg mse: 0.02114; lr: 0.00010: 100%|██████████| 3443/3443 [07:18<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test elbo: 0.01857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2; loss: 0.01791; mse: 0.01617; latent: 0.000; avg mse: 0.01787; lr: 0.00010: 100%|██████████| 3443/3443 [07:16<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test elbo: 0.01756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3; loss: 0.01756; mse: 0.01813; latent: 0.000; avg mse: 0.01754; lr: 0.00010:   2%|▏         | 79/3443 [00:15<10:46,  5.20it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# optimizer = optim.RMSprop(model.parameters(), lr=lr,weight_decay=1e-6,centered=True)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# sample_path = '../data/logs/vq-vae-2/4x/samples'\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# model_path = '../data/logs/vq-vae-2/4x/weights'\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# model_path = 'data/logs/emb_dim_1_n_embed_8192_bc_right_sub_left_minmax_4x_360'\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/logs/emb_dim_2_n_embed_8192_bc_left_9x_512_360\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PROJECTS\\python\\wc_cv\\ml\\pt_utils.py:381\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(cls, model, optimizer, train_loader, test_loader, model_path, epochs, device, latent_loss_weight, sample_size)\u001b[0m\n\u001b[0;32m    379\u001b[0m loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m latent_loss_weight \u001b[38;5;241m*\u001b[39m latent_loss\n\u001b[0;32m    380\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 381\u001b[0m train_mean_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# if scheduler is not None:\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m#     scheduler.step()\u001b[39;00m\n\u001b[0;32m    384\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 1e-4\n",
    "\n",
    "latent_loss_weight = 0.25\n",
    "sample_size = 25\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-7, amsgrad=True)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=lr,weight_decay=1e-6,centered=True)\n",
    "\n",
    "# sample_path = '../data/logs/vq-vae-2/4x/samples'\n",
    "# model_path = '../data/logs/vq-vae-2/4x/weights'\n",
    "\n",
    "# model_path = 'data/logs/emb_dim_1_n_embed_8192_bc_right_sub_left_minmax_4x_360'\n",
    "model_path = 'data/logs/emb_dim_2_n_embed_8192_bc_left_9x_512_360'\n",
    "\n",
    "Trainer.train(model=model, optimizer=optimizer, train_loader=train_loader, test_loader=test_loader,\n",
    "              model_path=model_path, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sample_path = '../data/logs/vq-vae-2/samples'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j, (img, label) in enumerate(test_loader):\n",
    "        img = img.to(device)\n",
    "        out, latent_loss = model(img)\n",
    "\n",
    "        sample_size = 25\n",
    "    sample = img[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sample = img[:sample_size]\n",
    "\n",
    "utils.save_image(\n",
    "    torch.cat([sample, out], 0),\n",
    "    f\"_vq_vae_2_test.png\",\n",
    "    nrow=sample_size,\n",
    "    normalize=True,\n",
    "    # range=(-1, 1),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
