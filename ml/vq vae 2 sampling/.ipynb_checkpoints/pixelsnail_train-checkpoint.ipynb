{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39af64a3-7a23-4b6b-bf8e-3254b925043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from apex import amp\n",
    "\n",
    "\n",
    "from pixelsnail import PixelSNAIL\n",
    "import os\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import lmdb\n",
    "from scheduler import CycleScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015288eb-4b12-43ad-830b-26a2359c6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDBDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.env = lmdb.open(\n",
    "            path,\n",
    "            max_readers=32,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "        )\n",
    "\n",
    "        if not self.env:\n",
    "            raise IOError('Cannot open lmdb dataset', path)\n",
    "\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            self.length = int(txn.get('length'.encode('utf-8')).decode('utf-8'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            key = str(index).encode('utf-8')\n",
    "\n",
    "            row = pickle.loads(txn.get(key))\n",
    "\n",
    "        return torch.from_numpy(row.top), torch.from_numpy(row.bottom), row.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3eb67a-2375-41be-94b9-560a79191096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epoch, loader, model, optimizer, scheduler, device):\n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (top, bottom, label) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        top = top.to(device)\n",
    "\n",
    "        if hier == 'top':\n",
    "            target = top\n",
    "            out, _ = model(top)\n",
    "\n",
    "        elif hier == 'bottom':\n",
    "            bottom = bottom.to(device)\n",
    "            target = bottom\n",
    "            out, _ = model(bottom, condition=top)\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == target).float()\n",
    "        accuracy = correct.sum() / target.numel()\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        loader.set_description(\n",
    "            (\n",
    "                f'epoch: {epoch + 1}; loss: {loss.item():.5f}; '\n",
    "                f'acc: {accuracy:.5f}; lr: {lr:.5f}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32249b51-e502-40ba-ab9b-d9399dda25c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'path' argument required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mLMDBDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     20\u001b[0m     dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hier \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mLMDBDataset.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m \u001b[43mlmdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_readers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreadahead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeminit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot open lmdb dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, path)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'path' argument required"
     ]
    }
   ],
   "source": [
    "batch=32\n",
    "epoch=420\n",
    "hier='top'\n",
    "lr=3e-4\n",
    "channel=256\n",
    "n_res_block=4\n",
    "n_res_channel=256\n",
    "n_out_res_block=0\n",
    "n_cond_res_block=3\n",
    "dropout=0.1\n",
    "amp='O0'\n",
    "sched=None\n",
    "ckpt=None\n",
    "path=None\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "dataset = LMDBDataset(path)\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=batch, shuffle=True, num_workers=4, drop_last=True\n",
    ")\n",
    "\n",
    "if hier == 'top':\n",
    "    model = PixelSNAIL(\n",
    "        [32, 32],\n",
    "        512,\n",
    "        channel,\n",
    "        5,\n",
    "        4,\n",
    "        n_res_block,\n",
    "        n_res_channel,\n",
    "        dropout=dropout,\n",
    "        n_out_res_block=n_out_res_block,\n",
    "    )\n",
    "\n",
    "elif hier == 'bottom':\n",
    "    model = PixelSNAIL(\n",
    "        [64, 64],\n",
    "        512,\n",
    "        channel,\n",
    "        5,\n",
    "        4,\n",
    "        n_res_block,\n",
    "        n_res_channel,\n",
    "        attention=False,\n",
    "        dropout=dropout,\n",
    "        n_cond_res_block=n_cond_res_block,\n",
    "        cond_res_channel=n_res_channel,\n",
    "    )\n",
    "\n",
    "\n",
    "if 'model' in ckpt:\n",
    "    model.load_state_dict(torch.load(ckpt))\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "scheduler = CycleScheduler(\n",
    "    optimizer, lr, n_iter=len(loader) * epoch, momentum=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b75d5-e1fd-43f3-a171-e4cb512de946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    train( i, loader, model, optimizer, scheduler, device)\n",
    "    torch.save(\n",
    "        {'model': model.module.state_dict(), ': ,\n",
    "        f'checkpoint/pixelsnail_{hier}_{str(i + 1).zfill(3)}.pt',\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
