{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12089de5-f4a5-42fc-b42b-b9457c515e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "\n",
    "except ImportError:\n",
    "    amp = None\n",
    "\n",
    "from dataset import LMDBDataset\n",
    "from pixelsnail import PixelSNAIL\n",
    "from scheduler import CycleScheduler\n",
    "from torch.utils import data\n",
    "\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed96dc6-0c6c-4a70-80d4-476d1dbed895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epoch, loader, model, optimizer, scheduler, device):\n",
    "    loader = tqdm(loader)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for i, (top, bottom, label) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        top = top.to(device)\n",
    "        bottom = bottom.to(device)\n",
    "\n",
    "        print(bottom.shape)\n",
    "        \n",
    "        if hier == 'top':\n",
    "            target = top\n",
    "            out, _ = model(top)\n",
    "\n",
    "        elif hier == 'bottom':\n",
    "            print('-1')\n",
    "            target = bottom\n",
    "            out, _ = model(bottom, condition=top)\n",
    "        \n",
    "            print('0')\n",
    "        \n",
    "        loss = criterion(out, target)\n",
    "        print(f'computed loss {loss}')\n",
    "        loss.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('1')\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == target).float()\n",
    "        accuracy = correct.sum() / target.numel()\n",
    "        print('2')\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        loader.set_description(\n",
    "            (\n",
    "                f'epoch: {epoch + 1}; loss: {loss.item():.5f}; '\n",
    "                f'acc: {accuracy:.5f}; lr: {lr:.5f}'\n",
    "            )\n",
    "        )\n",
    "    print(3)\n",
    "    return loss.item(), accuracy\n",
    "        \n",
    "def evaluate( epoch, loader, model, optimizer, scheduler, device):\n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for i, (top, bottom, label) in tqdm(enumerate(loader)):\n",
    "\n",
    "            top = top.to(device)\n",
    "            bottom = bottom.to(device)\n",
    "\n",
    "            top=torch.squeeze(top,[1])\n",
    "            bottom=torch.squeeze(bottom, [1])\n",
    "\n",
    "\n",
    "            if hier == 'top':\n",
    "                target = top\n",
    "                out, _ = model(top)\n",
    "\n",
    "            elif hier == 'bottom':\n",
    "                target = bottom\n",
    "                out, _ = model(bottom, condition=top)\n",
    "\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "            _, pred = out.max(1)\n",
    "            correct = (pred == target).float()\n",
    "            accuracy = correct.sum() / target.numel()\n",
    "\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            print(f'Test epoch: {epoch + 1}; loss: {loss.item():.5f}; acc: {accuracy:.5f}; lr: {lr:.5f}')\n",
    "\n",
    "            return loss.item(), accuracy\n",
    "\n",
    "\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()\n",
    "    \n",
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return data.SequentialSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848f6e44-8939-4abe-8e45-236034a3ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "lr=3e-4\n",
    "# hier='top'\n",
    "hier='bottom'\n",
    "epoch=420\n",
    "batch=4\n",
    "val_split=0.15\n",
    "n_gpu=1\n",
    "\n",
    "sched='cycle'\n",
    "\n",
    "dataset_path='runs/embs_emb_dim_2_n_embed_512_bc_left_4x_768'\n",
    "\n",
    "dataset = LMDBDataset(dataset_path)\n",
    "\n",
    "train_dataset_len = int(len(dataset) * (1 - val_split))\n",
    "test_dataset_len = len(dataset) - train_dataset_len\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_dataset_len, test_dataset_len],\n",
    "                                                            # generator=torch.Generator().manual_seed(seed)\n",
    "                                                           )\n",
    "\n",
    "train_sampler = data_sampler(train_dataset, shuffle=True, distributed=False)\n",
    "test_sampler = data_sampler(test_dataset, shuffle=True, distributed=False)\n",
    "\n",
    "# fails when numw_workers!=0\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch // n_gpu, sampler=train_sampler, num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch // n_gpu, sampler=test_sampler,num_workers=0,\n",
    ")\n",
    "\n",
    "\n",
    "channel=256\n",
    "dropout=0.1\n",
    "    \n",
    "    \n",
    "if hier == 'top':\n",
    "    \n",
    "    # original config\n",
    "    # n_res_channel=256\n",
    "    # n_out_res_block=0\n",
    "    # n_res_block=4\n",
    "    \n",
    "    # imagenet config\n",
    "    n_out_res_block=20\n",
    "    n_res_channel=2048\n",
    "    n_res_block=20\n",
    "\n",
    "    model = PixelSNAIL(\n",
    "        shape=[32, 32],\n",
    "        n_class=512,\n",
    "        channel=channel,\n",
    "        kernel_size=5,\n",
    "        n_block=4,\n",
    "        n_res_block=n_res_block,\n",
    "        res_channel=n_res_channel,\n",
    "        dropout=dropout,\n",
    "        cond_res_kernel=3,\n",
    "        attention=True,\n",
    "        cond_res_channel=0,\n",
    "        n_cond_res_block=0,\n",
    "        n_out_res_block=n_out_res_block,\n",
    "    )\n",
    "\n",
    "elif hier == 'bottom':\n",
    "    \n",
    "    # original config\n",
    "    # n_res_channel=256\n",
    "    # n_cond_res_block=3\n",
    "    # n_res_block=4\n",
    "    \n",
    "    # imagenet config\n",
    "    n_cond_res_block=20\n",
    "    n_res_channel=1024\n",
    "    n_res_block=20\n",
    "    \n",
    "    model = PixelSNAIL(\n",
    "        shape=[64, 64],\n",
    "        n_class=512,\n",
    "        channel=channel,\n",
    "        kernel_size=5,\n",
    "        n_block=4,\n",
    "        n_res_block=n_res_block,\n",
    "        res_channel=n_res_channel,\n",
    "        dropout=dropout,\n",
    "        cond_res_kernel=3,\n",
    "        attention=False,\n",
    "        cond_res_channel=n_res_channel,\n",
    "        n_cond_res_block=n_cond_res_block,\n",
    "        n_out_res_block=0,\n",
    " \n",
    "    )\n",
    "\n",
    "# if 'model' in ckpt:\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# if amp is not None:\n",
    "#     model, optimizer = amp.initialize(model, optimizer, opt_level=amp)\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "scheduler = None\n",
    "if sched == 'cycle':\n",
    "    scheduler = CycleScheduler(\n",
    "        optimizer, lr, n_iter=len(train_loader) * epoch, momentum=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fad8d2-7dd7-4617-b42f-321d770c8165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/383 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 64])\n",
      "-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "folder_name=f'runs/pixelsnail_emb_dim_2_n_embed_512_bc_left_4x_768_zeros/{hier}/'\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss, train_acc=train(i, train_loader, model, optimizer, scheduler, device)\n",
    "    loss, acc = evaluate( i, test_loader, model, optimizer, scheduler, device)\n",
    "    torch.save(model.state_dict(), f'{folder_name}/{str(i + 1)}_pixelsnail_{hier}_train_loss_{train_loss:2f}_acc_{train_acc:2f}_test_loss_{loss:2f}_acc_{acc:2f}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c3b00-8bf3-4446-9f25-46b3b524ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=f'runs/pixelsnail_emb_dim_64_n_embed_512_bc_left_4x_768/{hier}/'\n",
    "\n",
    "torch.save(model.state_dict(), f'{folder_name}/{str(i + 1)}_pixelsnail_{hier}_loss_{loss}_test_acc_{acc}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91708a10-7b51-4a4c-9673-6a1c006314fe",
   "metadata": {},
   "source": [
    "# Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88023aff-3765-4bc5-a5b3-8f655d88f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pixelsnail import PixelSNAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a49c0-2a28-4743-9aab-7b75ae144335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loader, model, optimizer, device):\n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (img, label) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "\n",
    "        out = model(img)\n",
    "        loss = criterion(out, img)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == img).float()\n",
    "        accuracy = correct.sum() / img.numel()\n",
    "\n",
    "        loader.set_description(\n",
    "            (f'epoch: {epoch + 1}; loss: {loss.item():.5f}; ' f'acc: {accuracy:.5f}')\n",
    "        )\n",
    "\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cuda'\n",
    "    epoch = 10\n",
    "\n",
    "    dataset = datasets.MNIST('.', transform=PixelTransform(), download=True)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "    model = PixelSNAIL([28, 28], 256, 128, 5, 2, 4, 128)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for i in range(10):\n",
    "        train(i, loader, model, optimizer, device)\n",
    "        torch.save(model.state_dict(), f'checkpoint/mnist_{str(i + 1).zfill(3)}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
