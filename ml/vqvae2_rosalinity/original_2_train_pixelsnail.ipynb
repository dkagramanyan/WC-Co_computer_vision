{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12089de5-f4a5-42fc-b42b-b9457c515e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "\n",
    "except ImportError:\n",
    "    amp = None\n",
    "\n",
    "from dataset import LMDBDataset\n",
    "from pixelsnail import PixelSNAIL\n",
    "from scheduler import CycleScheduler\n",
    "from torch.utils import data\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed96dc6-0c6c-4a70-80d4-476d1dbed895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epoch, loader, model, optimizer, scheduler, device):\n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (top, bottom, label) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        top = top.to(device)\n",
    "\n",
    "        if hier == 'top':\n",
    "            target = top\n",
    "            out, _ = model(top)\n",
    "\n",
    "        elif hier == 'bottom':\n",
    "            bottom = bottom.to(device)\n",
    "            target = bottom\n",
    "            out, _ = model(bottom, condition=top)\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == target).float()\n",
    "        accuracy = correct.sum() / target.numel()\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        loader.set_description(\n",
    "            (\n",
    "                f'epoch: {epoch + 1}; loss: {loss.item():.5f}; '\n",
    "                f'acc: {accuracy:.5f}; lr: {lr:.5f}'\n",
    "            )\n",
    "        )\n",
    "    return loss.item(), accuracy\n",
    "        \n",
    "def evaluate( epoch, loader, model, optimizer, scheduler, device):\n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for i, (top, bottom, label) in tqdm(enumerate(loader)):\n",
    "\n",
    "            top = top.to(device)\n",
    "            bottom = bottom.to(device)\n",
    "\n",
    "            top=torch.squeeze(top,[1])\n",
    "            bottom=torch.squeeze(bottom, [1])\n",
    "\n",
    "\n",
    "            if hier == 'top':\n",
    "                target = top\n",
    "                out, _ = model(top)\n",
    "\n",
    "            elif hier == 'bottom':\n",
    "                target = bottom\n",
    "                out, _ = model(bottom, condition=top)\n",
    "\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "            _, pred = out.max(1)\n",
    "            correct = (pred == target).float()\n",
    "            accuracy = correct.sum() / target.numel()\n",
    "\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            print(f'Test epoch: {epoch + 1}; loss: {loss.item():.5f}; acc: {accuracy:.5f}; lr: {lr:.5f}')\n",
    "\n",
    "            return loss.item(), accuracy\n",
    "\n",
    "\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()\n",
    "    \n",
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return data.SequentialSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848f6e44-8939-4abe-8e45-236034a3ee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "lr=3e-4\n",
    "hier='top'\n",
    "# hier='bottom'\n",
    "epoch=420\n",
    "batch=32\n",
    "val_split=0.15\n",
    "n_gpu=1\n",
    "\n",
    "sched='cycle'\n",
    "\n",
    "dataset_path='runs/embs_emb_dim_64_n_embed_512_bc_left_4x_768'\n",
    "\n",
    "dataset = LMDBDataset(dataset_path)\n",
    "\n",
    "train_dataset_len = int(len(dataset) * (1 - val_split))\n",
    "test_dataset_len = len(dataset) - train_dataset_len\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_dataset_len, test_dataset_len],\n",
    "                                                            # generator=torch.Generator().manual_seed(seed)\n",
    "                                                           )\n",
    "\n",
    "train_sampler = data_sampler(train_dataset, shuffle=True, distributed=False)\n",
    "test_sampler = data_sampler(test_dataset, shuffle=True, distributed=False)\n",
    "\n",
    "# fails when numw_workers!=0\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch // n_gpu, sampler=train_sampler, num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch // n_gpu, sampler=test_sampler,num_workers=0,\n",
    ")\n",
    "\n",
    "\n",
    "channel=256\n",
    "dropout=0.1\n",
    "    \n",
    "    \n",
    "if hier == 'top':\n",
    "    \n",
    "    # original config\n",
    "    # n_res_channel=256\n",
    "    # n_out_res_block=0\n",
    "    # n_res_block=4\n",
    "    \n",
    "    # imagenet config\n",
    "    n_out_res_block=20\n",
    "    n_res_channel=2048\n",
    "    n_res_block=20\n",
    "\n",
    "    model = PixelSNAIL(\n",
    "        shape=[32, 32],\n",
    "        n_class=512,\n",
    "        channel=channel,\n",
    "        kernel_size=5,\n",
    "        n_block=4,\n",
    "        n_res_block=n_res_block,\n",
    "        res_channel=n_res_channel,\n",
    "        dropout=dropout,\n",
    "        cond_res_kernel=3,\n",
    "        attention=True,\n",
    "        cond_res_channel=0,\n",
    "        n_cond_res_block=0,\n",
    "        n_out_res_block=n_out_res_block,\n",
    "    )\n",
    "\n",
    "elif hier == 'bottom':\n",
    "    \n",
    "    # original config\n",
    "    # n_res_channel=256\n",
    "    # n_cond_res_block=3\n",
    "    # n_res_block=4\n",
    "    \n",
    "    # imagenet config\n",
    "    n_cond_res_block=20\n",
    "    n_res_channel=1024\n",
    "    n_res_block=20\n",
    "    \n",
    "    model = PixelSNAIL(\n",
    "        shape=[64, 64],\n",
    "        n_class=512,\n",
    "        channel=channel,\n",
    "        kernel_size=5,\n",
    "        n_block=4,\n",
    "        n_res_block=n_res_block,\n",
    "        res_channel=n_res_channel,\n",
    "        dropout=dropout,\n",
    "        cond_res_kernel=3,\n",
    "        attention=False,\n",
    "        cond_res_channel=n_res_channel,\n",
    "        n_cond_res_block=n_cond_res_block,\n",
    "        n_out_res_block=0,\n",
    " \n",
    "    )\n",
    "\n",
    "# if 'model' in ckpt:\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# if amp is not None:\n",
    "#     model, optimizer = amp.initialize(model, optimizer, opt_level=amp)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "scheduler = None\n",
    "if sched == 'cycle':\n",
    "    scheduler = CycleScheduler(\n",
    "        optimizer, lr, n_iter=len(train_loader) * epoch, momentum=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fad8d2-7dd7-4617-b42f-321d770c8165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1; loss: 2.45584; acc: 0.28659; lr: 0.00001:  56%|████████████████▉             | 27/48 [00:25<00:19,  1.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m folder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/pixelsnail_emb_dim_64_n_embed_512_bc_left_4x_768/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[1;32m----> 4\u001b[0m     train_loss, train_acc\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m evaluate( i, test_loader, model, optimizer, scheduler, device)\n\u001b[0;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pixelsnail_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train_loss_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_acc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test_loss_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_acc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, loader, model, optimizer, scheduler, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m correct\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m target\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m     31\u001b[0m     lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     33\u001b[0m     loader\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[0;32m     34\u001b[0m         (\n\u001b[1;32m---> 35\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     37\u001b[0m         )\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), accuracy\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_name=f'runs/pixelsnail_emb_dim_64_n_embed_512_bc_left_4x_768/{hier}/'\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss, train_acc=train(i, train_loader, model, optimizer, scheduler, device)\n",
    "    loss, acc = evaluate( i, test_loader, model, optimizer, scheduler, device)\n",
    "    torch.save(model.state_dict(), f'{folder_name}/{str(i + 1)}_pixelsnail_{hier}_train_loss_{train_loss:2f}_acc_{train_acc:2f}_test_loss_{loss:2f}_acc_{acc:2f}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c3b00-8bf3-4446-9f25-46b3b524ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=f'runs/pixelsnail_emb_dim_64_n_embed_512_bc_left_4x_768/{hier}/'\n",
    "\n",
    "torch.save(model.state_dict(), f'{folder_name}/{str(i + 1)}_pixelsnail_{hier}_loss_{loss}_test_acc_{acc}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91708a10-7b51-4a4c-9673-6a1c006314fe",
   "metadata": {},
   "source": [
    "# Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88023aff-3765-4bc5-a5b3-8f655d88f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pixelsnail import PixelSNAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a49c0-2a28-4743-9aab-7b75ae144335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loader, model, optimizer, device):\n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (img, label) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "\n",
    "        out = model(img)\n",
    "        loss = criterion(out, img)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == img).float()\n",
    "        accuracy = correct.sum() / img.numel()\n",
    "\n",
    "        loader.set_description(\n",
    "            (f'epoch: {epoch + 1}; loss: {loss.item():.5f}; ' f'acc: {accuracy:.5f}')\n",
    "        )\n",
    "\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cuda'\n",
    "    epoch = 10\n",
    "\n",
    "    dataset = datasets.MNIST('.', transform=PixelTransform(), download=True)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "    model = PixelSNAIL([28, 28], 256, 128, 5, 2, 4, 128)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for i in range(10):\n",
    "        train(i, loader, model, optimizer, device)\n",
    "        torch.save(model.state_dict(), f'checkpoint/mnist_{str(i + 1).zfill(3)}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
