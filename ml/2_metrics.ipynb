{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c1b6d-5745-47ba-8a13-14905545b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from scheduler import CycleScheduler\n",
    "from pt_utils import  Embeddings, Trainer, VQVAE, data_sampler, Vqvae2Adaptive\n",
    "from torch.utils import data\n",
    "from torch import distributed as dist\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from skimage import transform, metrics\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# from tqdm.notebook import trange, tqdm\n",
    "from tqdm import trange, tqdm\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "seed = 51\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ccf5a-819c-41e4-a6a0-08819d10b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_losses = []\n",
    "ssim_losses = []\n",
    "\n",
    "visual_loader = DataLoader(\n",
    "    dataset, batch_size=1, num_workers=2\n",
    ")\n",
    "\n",
    "for i, (img, label) in enumerate(visual_loader):\n",
    "    model.zero_grad()\n",
    "    img = img.to(device)\n",
    "\n",
    "    out, latent_loss = model(img)\n",
    "    predicted_image = np.transpose(out.cpu().detach().numpy()[0])\n",
    "    original_image = np.transpose(img.cpu().detach().numpy()[0])\n",
    "\n",
    "    mse_losses.append(metrics.mean_squared_error(original_image, predicted_image))\n",
    "    ssim_losses.append(metrics.structural_similarity(original_image, predicted_image, multichannel=True))\n",
    "\n",
    "mse_losses = np.array(mse_losses)\n",
    "ssim_losses = np.array(ssim_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c976a10-95bb-4534-9fe5-438c2321e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mse = pd.DataFrame()\n",
    "df_ssim = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c2976-3fff-4a95-8d6e-07a24190aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n",
    "\n",
    "names = ['Ultra_Co8\\nсредние зерна', 'Ultra_Co11\\nмелкие зерна', 'Ultra_Co6_2\\nмелкие зерна',\n",
    "         'Ultra_Co15\\nкрупные зерна', 'Ultra_Co25\\nсредне-мелкие зерна']\n",
    "\n",
    "colors = ['b', 'g', 'y', 'm', 'c']\n",
    "markers = ['8', 'v', 's', 'd', '*', ]\n",
    "\n",
    "f_vects = []\n",
    "\n",
    "cnt = Counter(np.array(dataset.samples)[:, 1])\n",
    "\n",
    "for i in cnt.keys():\n",
    "    emb_number = cnt[i]\n",
    "    key = int(i)\n",
    "\n",
    "    start = 0\n",
    "    for val in range(int(i)):\n",
    "        start += cnt[str(val)]\n",
    "\n",
    "    end = start + emb_number\n",
    "\n",
    "    mse_y = mse_losses[start:end]\n",
    "    ssim_y = ssim_losses[start:end]\n",
    "\n",
    "    df_mse[names[key]] = pd.Series(mse_y)\n",
    "    df_ssim[names[key]] = pd.Series(ssim_y)\n",
    "\n",
    "plt.rcParams['font.size'] = '20'\n",
    "\n",
    "# plt.ylabel('MSE loss', fontsize=20)\n",
    "name = 'vq-vae-2'\n",
    "# plt.savefig(f'mse_ssim_losses_{name}_512.png')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede01f8-cfef-4073-926c-8dd7bcdf3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = '15'\n",
    "name = 'vq-vae-2'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 12))\n",
    "# plt.figure(figsize=(10,10))\n",
    "df_ssim.boxplot(ax=ax2)\n",
    "df_mse.boxplot(ax=ax1)\n",
    "\n",
    "ax1.set_ylabel('MSE loss', fontsize=20)\n",
    "ax2.set_ylabel('SSIM similarity', fontsize=20)\n",
    "\n",
    "plt.savefig(f'mse_ssim_losses_{name}_512_boxplot.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
