{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from skimage import transform, metrics\n",
    "from umap import UMAP\n",
    "import datetime\n",
    "from scipy.signal import argrelextrema\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skimage import io\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "import plotly.express as px\n",
    "\n",
    "from src.utils import GrainLogs\n",
    "from src.nn import RSU7, RSU6, RSU5, RSU4, RSU4F, ConvBlock\n",
    "from src.nn_utils import SaveImageCallback\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, label_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.stage1 = RSU7(16, 32)\n",
    "        self.pool12 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage2 = RSU6(32, 64)\n",
    "        self.pool23 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage3 = RSU5(64, 128)\n",
    "        self.pool34 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "        self.stage4 = RSU4(128, 256)\n",
    "        self.pool45 = layers.MaxPool2D((2, 2), 2)\n",
    "        #out_w_h=64\n",
    "\n",
    "        self.stage5 = RSU4F(256, 256)\n",
    "        self.pool56 = layers.MaxPool2D((2, 2), 2)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        #Encoder block 1\n",
    "\n",
    "        hx1 = self.stage1(inputs)\n",
    "\n",
    "        hx = self.pool12(hx1)\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        hx5 = self.stage5(hx)\n",
    "        x = self.pool56(hx5)\n",
    "        global_pool = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(global_pool)\n",
    "        x = tf.keras.layers.Dense(512)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(self.latent_dim + self.latent_dim)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "        x_label = layers.Dense(128)(global_pool)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "        x_label = layers.Dense(self.label_dim, name='encoder_label_output')(x_label)\n",
    "        x_label = layers.LeakyReLU()(x_label)\n",
    "\n",
    "        # tf.keras.layers.InputLayer(input_shape=(28, 28, 1))\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=32, kernel_size=3, strides=(2, 2), activation='relu')(inputs)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=64, kernel_size=3, strides=(2, 2), activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        # No activation\n",
    "        x = tf.keras.layers.Dense(latent_dim + latent_dim)(x)\n",
    "\n",
    "        # return x, x_label\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, label_dim, batch_size=32, out_ch=1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.label_dim = label_dim\n",
    "        self.out_ch = out_ch\n",
    "\n",
    "        self.stage6 = RSU4F(256, 256)\n",
    "        self.stage5d = RSU4F(128, 128)\n",
    "        self.stage4d = RSU4(64, 64)\n",
    "        self.stage3d = RSU5(32, 32)\n",
    "        self.stage2d = RSU6(16, out_ch)\n",
    "        self.stage1d = RSU7(16, out_ch)\n",
    "\n",
    "    def __call__(self, z_inputs):\n",
    "        # Reshape input\n",
    "        # z_image_v, labels = tf.split(z_inputs, axis=1, num_or_size_splits=2)\n",
    "        # z_data = tf.concat(z_inputs, axis=1)\n",
    "        x = layers.Dense(1024)(z_inputs)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.3)\n",
    "\n",
    "        x = layers.Dense(512)(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.3)\n",
    "\n",
    "        x = layers.Dense(256)(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.3)\n",
    "\n",
    "        x = layers.Reshape(target_shape=(16, 16, 1))(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU4F(256, 256)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU4F(128, 128)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU4(64, 64)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU5(32, 32)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU6(16, 16)(x)\n",
    "\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        x = RSU6(8, self.out_ch)(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(units=7 * 7 * 32, activation=tf.nn.relu)(z_inputs)\n",
    "        x = tf.keras.layers.Reshape(target_shape=(7, 7, 32))(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=64, kernel_size=3, strides=2, padding='same',\n",
    "            activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=32, kernel_size=3, strides=2, padding='same',\n",
    "            activation='relu')(x)\n",
    "        # No activation\n",
    "        x = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=1, kernel_size=3, strides=1, padding='same')(x)\n",
    "\n",
    "        # x = activations.sigmoid(x)\n",
    "\n",
    "        # return x, x_label\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# latent_dim = (200,)\n",
    "# label_dim = (5,)\n",
    "#\n",
    "# decoder = Decoder(label_dim=5)\n",
    "# z_input = layers.Input(shape=latent_dim)\n",
    "# label_input = layers.Input(shape=label_dim)\n",
    "# outputs = decoder([z_input, label_input])\n",
    "#\n",
    "# model = tf.keras.Model(inputs=[z_input, label_input], outputs=outputs)\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model=tf.keras.applications.VGG19(include_top=False,input_shape=(64,64,3))\n",
    "# tf.keras.utils.plot_model(model, to_file='cvae_1.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "images_dataset = (x_train / 255).reshape((-1, 28, 28, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = np.load('data/saved np/images_no_filters.npy')\n",
    "\n",
    "grain_names = np.array(\n",
    "    [['Ultra_Co8.jpg'], ['Ultra_Co11.jpg'], ['Ultra_Co6_2.jpg'], ['Ultra_Co15.jpg'], ['Ultra_Co25.jpg']])\n",
    "\n",
    "labels = np.array([[91, 12.1, 1210],\n",
    "                   [78, 8.1, 1180],\n",
    "                   [62, 8.9, 1100],\n",
    "                   [72, 21.6, 990],\n",
    "                   [99, 15.3, 1200]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "\n",
    "labels_dataset = []\n",
    "for i in range(images.shape[0]):\n",
    "    for j in range(images.shape[1]):\n",
    "        labels_dataset.append(labels[i])\n",
    "\n",
    "images_dataset = images.reshape((-1, 1024, 1024, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_images, test_images = train_test_split(images_dataset, test_size=0.2, random_state=421)\n",
    "# train_labels, test_labels = train_test_split(labels_dataset, test_size=0.2, random_state=421)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Checkpoint path\n",
    "# checkpoint_root = \"./CVAE{}_{}_checkpoint\".format(latent_dim, beta)\n",
    "# checkpoint_name = \"model\"\n",
    "# save_prefix = os.path.join(checkpoint_root, checkpoint_name)\n",
    "#\n",
    "# # Define the checkpoint\n",
    "# checkpoint = tf.train.Checkpoint(module=cvae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "class ConvCVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 label_dim,\n",
    "                 latent_dim,\n",
    "                 beta=1,\n",
    "                 batch_size=2\n",
    "                 ):\n",
    "        super(ConvCVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, label_dim=label_dim)\n",
    "        self.decoder = Decoder(label_dim=label_dim)\n",
    "        self.label_dim = label_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n",
    "            # eps = tf.random.normal(shape=(self.latent_dim,))\n",
    "        return self.decode(eps, apply_sigmoid=False)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "\n",
    "        eps = tf.random.normal(shape=(self.batch_size,self.latent_dim))\n",
    "        # eps = tf.random.normal(shape=(self.latent_dim,))\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# def compute_loss(model, x):\n",
    "#     z_mean, z_log_var = model.encode(x)\n",
    "#     z = model.reparameterize(z_mean, z_log_var)\n",
    "#     logits = model.decode(z, apply_sigmoid=False)\n",
    "#     rec_loss = tf.cast(tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits, x)), tf.float32)\n",
    "#     # rec_loss = tf.cast(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=x), 1), tf.float32)\n",
    "#     latent_loss = tf.cast(\n",
    "#         tf.reduce_mean(-0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)),\n",
    "#         tf.float32)\n",
    "#\n",
    "#     total_loss = rec_loss + beta * latent_loss\n",
    "#     # print(\n",
    "#     #     f'total loss {total_loss}, reconstr_loss {rec_loss}, latent_loss {latent_loss}')\n",
    "#\n",
    "#     return total_loss, rec_loss, latent_loss\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x),0,0\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        total_loss, rec_loss, latent_loss = compute_loss(model, x)\n",
    "\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return total_loss, rec_loss, latent_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    logits = activations.sigmoid(model.sample(z))\n",
    "    prediction = logits.numpy()[0] * 255\n",
    "    io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def printProgressBar(epoch, iteration, total, prefix='', suffix='', decimals=1, length=100, fill='█', printEnd=\"\\r\",\n",
    "                     eta=None, loss=None, train_type='train'):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(\n",
    "        f'\\r{prefix} |{bar}| {percent}% {suffix} ETA:{eta} s epoch={epoch}: ELBO={str(np.round(loss[0], 4))},rec_loss={str(np.round(loss[1], 4))} lat_loss={str(round(loss[2], 4))}',\n",
    "        end=printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 200\n",
    "label_dim = 3\n",
    "\n",
    "model = ConvCVAE(label_dim, latent_dim,batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=1: ELBO=543.9858,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 1, Test set ELBO: 542.7450561523438, time elapse for current epoch: 24.30491590499878\n",
      "Progress: |█| 100.0% Complete ETA:None s epoch=2: ELBO=544.0162,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 2, Test set ELBO: 544.2404174804688, time elapse for current epoch: 24.031843185424805\n",
      "Progress: |-| 0.1% Complete ETA:None s epoch=3: ELBO=548.5278,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0002.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=3: ELBO=543.6212,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 3, Test set ELBO: 544.892822265625, time elapse for current epoch: 24.142455339431763\n",
      "Progress: |-| 0.1% Complete ETA:None s epoch=4: ELBO=553.768,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0003.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=4: ELBO=543.7947,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 4, Test set ELBO: 544.6715698242188, time elapse for current epoch: 24.096307516098022\n",
      "Progress: |█| 100.0% Complete ETA:None s epoch=5: ELBO=543.6124,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 5, Test set ELBO: 543.5389404296875, time elapse for current epoch: 24.09579849243164\n",
      "Progress: |-| 0.1% Complete ETA:None s epoch=6: ELBO=561.7578,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0005.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=6: ELBO=544.1609,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 6, Test set ELBO: 544.3749389648438, time elapse for current epoch: 24.064552545547485\n",
      "Progress: |-| 0.1% Complete ETA:None s epoch=7: ELBO=527.9998,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0006.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=7: ELBO=544.4928,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 7, Test set ELBO: 544.2960205078125, time elapse for current epoch: 23.924988985061646\n",
      "Progress: |-| 0.3% Complete ETA:None s epoch=8: ELBO=542.4243,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0007.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=8: ELBO=543.3864,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 8, Test set ELBO: 543.8588256835938, time elapse for current epoch: 24.096721410751343\n",
      "Progress: |█| 100.0% Complete ETA:None s epoch=9: ELBO=544.1161,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 9, Test set ELBO: 544.4686279296875, time elapse for current epoch: 24.097524642944336\n",
      "Progress: |-| 0.3% Complete ETA:None s epoch=10: ELBO=541.5878,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0009.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=10: ELBO=543.9997,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 10, Test set ELBO: 544.7211303710938, time elapse for current epoch: 24.043173789978027\n",
      "Progress: |-| 0.1% Complete ETA:None s epoch=11: ELBO=554.7797,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0010.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█| 100.0% Complete ETA:None s epoch=11: ELBO=544.3544,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 11, Test set ELBO: 543.92041015625, time elapse for current epoch: 24.020835399627686\n",
      "Progress: |█| 100.0% Complete ETA:None s epoch=12: ELBO=544.3468,rec_loss=0.0 lat_loss=0.0\r\n",
      "Epoch: 12, Test set ELBO: 543.51953125, time elapse for current epoch: 23.97903347015381\n",
      "Progress: |-| 0.1% Complete ETA:None s epoch=13: ELBO=541.6345,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7578ee8870af>:6: UserWarning: image_at_epoch_0012.png is a low contrast image\n",
      "  io.imsave('image_at_epoch_{:04d}.png'.format(epoch), prediction.astype(np.uint8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |-| 22.8% Complete ETA:None s epoch=13: ELBO=544.3606,rec_loss=0.0 lat_loss=0.0\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-65-daf6fd0f6d38>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;31m# print(f'epoch={epoch} batch num={i}/{n_batches}')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrec_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlatent_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_images_dataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[0mtotal_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m         \u001B[0mtotal_rec_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrec_loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-62-19b8d2c6fc13>\u001B[0m in \u001B[0;36mtrain_step\u001B[1;34m(model, x, optimizer)\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mtotal_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrec_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlatent_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m     \u001B[0mgradients\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtotal_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtotal_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrec_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlatent_loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36mgradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1078\u001B[0m                           for x in nest.flatten(output_gradients)]\n\u001B[0;32m   1079\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1080\u001B[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001B[0m\u001B[0;32m   1081\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1082\u001B[0m         \u001B[0mflat_targets\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001B[0m in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     69\u001B[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 71\u001B[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001B[0m\u001B[0;32m     72\u001B[0m       \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m       \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36m_gradient_function\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    160\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    161\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 162\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    163\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001B[0m in \u001B[0;36m_Conv2DBackpropInputGrad\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m     45\u001B[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001B[0;32m     46\u001B[0m           \u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m           \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m           \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m           \u001B[0mdilations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_attr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dilations\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mshape\u001B[1;34m(input, name, out_type)\u001B[0m\n\u001B[0;32m    647\u001B[0m     \u001B[0mA\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mout_type\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    648\u001B[0m   \"\"\"\n\u001B[1;32m--> 649\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mshape_internal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    650\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    651\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mshape_internal\u001B[1;34m(input, name, optimize, out_type)\u001B[0m\n\u001B[0;32m    675\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0moptimize\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_fully_defined\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    676\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 677\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    678\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001B[0m in \u001B[0;36mshape\u001B[1;34m(input, out_type, name)\u001B[0m\n\u001B[0;32m   9154\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   9155\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 9156\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m   9157\u001B[0m         _ctx, \"Shape\", name, input, \"out_type\", out_type)\n\u001B[0;32m   9158\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# generate_and_save_images(model, 0, test_sample)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3,centered=True)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "batch_size = 64\n",
    "beta = 1\n",
    "\n",
    "n_batches = train_images.shape[0] // batch_size\n",
    "n_batches_test = test_images.shape[0] // batch_size\n",
    "model.batch_size = batch_size\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images.astype(np.float32)).batch(\n",
    "        batch_size).as_numpy_iterator()\n",
    "    test_images_dataset = tf.data.Dataset.from_tensor_slices(test_images.astype(np.float32)).batch(\n",
    "        batch_size).as_numpy_iterator()\n",
    "\n",
    "    start_time = time.time()\n",
    "    total_loss = []\n",
    "    total_rec_loss = []\n",
    "    total_latent_loss = []\n",
    "\n",
    "    printProgressBar(epoch, 0, n_batches, eta=None, loss=[0, 0, 0], prefix='Progress:', suffix='Complete',\n",
    "                     train_type='train', length=1)\n",
    "    for i, train_x in enumerate(range(n_batches)):\n",
    "        # print(f'epoch={epoch} batch num={i}/{n_batches}')\n",
    "\n",
    "        loss, rec_loss, latent_loss = train_step(model, train_images_dataset.next(), optimizer)\n",
    "        total_loss.append(loss)\n",
    "        total_rec_loss.append(rec_loss)\n",
    "        total_latent_loss.append(latent_loss)\n",
    "        printProgressBar(epoch, i + 1, n_batches, eta=None, prefix='Progress:', suffix='Complete', train_type='train',\n",
    "                         loss=[np.mean(total_loss), np.mean(rec_loss), np.mean(total_latent_loss)], length=1)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for i, test_x in enumerate(range(n_batches_test)):\n",
    "        loss(compute_loss(model, test_images_dataset.next())[0])\n",
    "    elbo = loss.result()\n",
    "    # display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "          .format(epoch, elbo, end_time - start_time))\n",
    "    test_sample = test_images[np.random.randint(0, test_images.shape[0])]\n",
    "    generate_and_save_images(model, epoch, np.expand_dims(test_sample, axis=0).astype(np.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(1024, input_shape=(400,)))\n",
    "model.add(layers.Reshape((32, 32, 1)))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4F(256, 512))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4F(128, 256))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4(64, 128))\n",
    "model.add(layers.UpSampling2D(size=(2, 2), interpolation='bilinear'))\n",
    "model.add(RSU4(32, 64))\n",
    "model.add(layers.Conv2DTranspose(16, kernel_size=(2, 2), strides=(2, 2)))\n",
    "# model.add(RSU4(16, 1))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}